<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ordina-jworks.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ordina-jworks.github.io/" rel="alternate" type="text/html" /><updated>2020-04-03T07:24:09+00:00</updated><id>https://ordina-jworks.github.io/feed.xml</id><title type="html">Ordina JWorks Tech Blog</title><subtitle>We build innovative solutions with Java and JavaScript. To support this mission, we have several Competence Centers. From within those Competence Centers, we provide coaching to the employee and expert advice towards our customer. In order to keep in sync with the latest technologies and the latest trends, we frequently visit conferences around the globe.
</subtitle><entry><title type="html">DevOpsDays 2019</title><link href="https://ordina-jworks.github.io/conference/2020/03/31/DevOpsDays-2019.html" rel="alternate" type="text/html" title="DevOpsDays 2019" /><published>2020-03-31T00:00:00+00:00</published><updated>2020-03-31T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/conference/2020/03/31/DevOpsDays-2019</id><content type="html" xml:base="https://ordina-jworks.github.io/conference/2020/03/31/DevOpsDays-2019.html">&lt;blockquote&gt;
  &lt;p&gt;The 7th edition of DevOpsDays Amsterdam in ‘Pakhuis de Zwijger’ was my first experience with &lt;a href=&quot;https://devopsdays.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;DevOpsDays&lt;/a&gt;. 
I’d like to share some talks and my impressions about the conference, because sharing ideas worth spreading is what we aim for at JWorks.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img alt=&quot;Conference crowd outside&quot; src=&quot;/img/2020-03-31-devopsdays/devopsdays.jpg&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 1050px;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of contents&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#observability-for-emerging-infra-what-got-you-here-wont-get-you-there-by-charity-majors&quot;&gt;Observability for Emerging Infra: What Got You Here Won’t Get You There, by Charity Majors&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-convenience-is-killing-open-standards-by-bernd-erk&quot;&gt;How Convenience is Killing Open Standards, by Bernd Erk&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#come-listen-to-me-im-a-fraud-by-joep-piscaer&quot;&gt;Come Listen to me, I’m a fraud, by Joep Piscaer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#fight-flight-or-freeze--releasing-organizational-trauma-by-matty-stratton&quot;&gt;Fight, Flight or Freeze – Releasing Organizational Trauma, by Matty Stratton&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;observability-for-emerging-infra-what-got-you-here-wont-get-you-there-by-charity-majors&quot;&gt;Observability for Emerging Infra: What Got You Here Won’t Get You There, by Charity Majors&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img class=&quot;p-image&quot; alt=&quot;Charity Majors&quot; src=&quot;/img/2020-03-31-devopsdays/charity-majors.jpg&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/mipsytipsy&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Charity Majors&lt;/a&gt; is a co-founder and engineer at &lt;a href=&quot;https://www.honeycomb.io&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Honeycomb.io&lt;/a&gt;, a monitoring and analyzer tool that can gather information from various sources to provide an overview of what’s happening in your (production) environment.&lt;/p&gt;

&lt;p&gt;Most of you have experience with sieving information through logs and analyzing all kinds of dashboards to find and fully understand what went wrong in your application. 
Finding and understanding the data can be really hard. 
You lack the bigger picture because the tools for doing metrics, logging and tracing (what she calls the “three pillars of observability”) have their own benefits and drawbacks.&lt;/p&gt;

&lt;p&gt;Logs can be useful for compliance reasons but they are not so great to picture the context. 
Metric tools might be more visual than logs, but they are less suitable for debugging purposes or to completely understand why something failed.
&lt;img alt=&quot;Observability venn diagram&quot; src=&quot;/img/2020-03-31-devopsdays/Observability.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We as human beings like visual representation to easily perceive why certain situations occurred. 
For example during and after deploying new versions because the chance is higher that something will go wrong. 
According to Charity, deployments are not like ‘flipping a binary switch’. 
It’s more like a step in a long process of being confident in your code that it will work on other environments rather than just on your local machine or development environment.&lt;/p&gt;

&lt;p&gt;Especially deployments to production will not always go as planned and it will be even more difficult to do so, since infrastructure has become more complex over the recent years. 
We see our infrastructure changing from simple &lt;a href=&quot;https://en.wikipedia.org/wiki/LAMP_(software_bundle)&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;LAMP&lt;/a&gt; stacks to replica sets, nodes and micro-service architectures.&lt;/p&gt;

&lt;p&gt;It would be very difficult to quickly grasp what’s going on with your applications and its underlying systems without good observability.&lt;/p&gt;

&lt;p&gt;Observability is a measure of how well internal states of a system can be inferred from knowledge of its external outputs.
It has the advantages of logging, tracing and metrics, and could be achieved with the right tools, if set up correctly. This is what Honeycomb is trying to achieve.&lt;/p&gt;

&lt;p&gt;Charity states that observability is not the same as monitoring. 
That is because monitoring is more like a ‘post-talk’ approach in her eyes. 
You’re typically too late and the damage has already been done upon discovery.
Monitoring systems have not changed significantly in twenty years and have fallen behind the way we build software. 
Software nowadays consists of large distributed systems that are made up of many non-uniform interacting components, while the core functionality of monitoring systems has stagnated.&lt;/p&gt;

&lt;h2 id=&quot;how-convenience-is-killing-open-standards-by-bernd-erk&quot;&gt;How Convenience is Killing Open Standards, by Bernd Erk&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img class=&quot;p-image&quot; alt=&quot;Bernd Erk&quot; src=&quot;/img/2020-03-31-devopsdays/bernd-erk.jpg&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;You may know that migrating configurations from one cloud provider to another can be challenging.
Cloud providers are mostly lacking an ‘open standard’ to make it easier. 
&lt;a href=&quot;https://twitter.com/gethash&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Bernd&lt;/a&gt;’s talk wants us to think about what Open Standards and Open Source could bring to us and how they have led to the success of Linux and Open Source communities we have today.&lt;/p&gt;

&lt;p&gt;In his early career, Bernd was a Solaris system engineer who maintained more than just Solaris systems within his company such as Unix-like systems &lt;a href=&quot;https://en.wikipedia.org/wiki/IBM_AIX&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AIX&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/HP-UX&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;HP-UX&lt;/a&gt;.
Managing unfamiliar platforms was hard, but luckily, most *NIX systems are relying on the POSIX standard. 
POSIX made it possible to develop other libraries such as GNU tools so they weren’t forced to use Sun’s (proprietary) freeware for instance. 
Fast-forwarding to 2019, we see that open source is becoming more popular than ever before. 
However, regarding Open Standards, there is still some work to do.&lt;/p&gt;

&lt;p&gt;The market has changed over the recent decade. 
Public and hybrid cloud are emerging and on-premise deployment is declining. 
We see that especially AWS and Azure have been expanding in the recent years as more and more customers are using their services. 
All those cloud providers like AWS, Google Cloud, Azure,… have their own APIs and those are not interchangeable since they are lacking a standard. 
The fact that an API is open does not imply that it is a standard, it’s only something you have access to. 
That is why tools like &lt;a href=&quot;https://www.terraform.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Terraform&lt;/a&gt; are becoming popular. 
People have a need for a unified standard to manage their resources. 
Bernd thinks that Open Source is very important to have open standards although those are not the same.&lt;/p&gt;

&lt;p&gt;There is also a problem if a certain cloud provider uses Open Software. 
If they use a certain piece of open source software, there is no direct connection between the customer and the original developer of that software, because that layer was cut. 
No matter what business model, the creator of the software has to earn money.&lt;/p&gt;

&lt;p&gt;Open Source tools in the cloud make sure that you have direct contact to the creators of the software to help you out. 
AWS, on the other hand, has their own versions of Open Source Software like Open Distro which is basically their own distribution of ElasticSearch. 
This removes the connection with the original developer, because you can only contact them for support. 
It brings fear and protection to the developers of the software because they are afraid that money and intellectual property goes away. 
That’s the reason why they came up with own licenses like Server-Side Public License (SSPL) that MongoDB uses, for instance. 
This tells you that if you alter it to sell it as a SaaS offering, you have to contribute to that code.
And Redis prohibits you to sell their enterprise model as their cloud solution.&lt;/p&gt;

&lt;p&gt;Bernd doesn’t like that people come up with new licenses, but he also understands that they are afraid that their money stream would go away, and they see this as a possible solution. 
We have to see that we support enough Open Source and Open Standards, because they need it to improve and maintain their software or service.&lt;/p&gt;

&lt;p&gt;In today’s oligopoly of cloud providers, it’s really difficult to new players to emerge their new business, although this will be good to have a more diverse internet. 
Most companies are focusing on the more human side of things when it comes to diversity, which is great, but there is a lot of work on the technology side as well.
He compares it to when there are only a few companies that control the availability of Insulin because there’s no market law to reduce prices. 
It would be a lot cheaper if there were more players that provide Insulin.
“Abuse of Power comes as no surprise”.&lt;/p&gt;

&lt;p&gt;At the end of his talk, he draws some conclusions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Be reasonable&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Think about what you are doing.&lt;/li&gt;
  &lt;li&gt;It must be easier for new players to enter the cloud market, with the help of open standards.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Interoperability is important&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You can easily work with different services from different providers so you can work together.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Support variety&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Try to be out there and have a look on the industry on how it is. Think about what your next move will be.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Demand contribution&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Demand as a customer what you want to obtain from your provider.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Diversity is up to you&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Demand more diversity on the technical level.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;come-listen-to-me-im-a-fraud-by-joep-piscaer&quot;&gt;Come Listen to me, I’m a fraud, by Joep Piscaer&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img class=&quot;p-image&quot; alt=&quot;Joep Piscaer&quot; src=&quot;/img/2020-03-31-devopsdays/joep-piscaer.jpg&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“&lt;em&gt;Do you tend to chalk your accomplishments up to luck or timing&lt;/em&gt;”; “&lt;em&gt;do you hate making a mistake, being less than fully prepared or not doing things perfectly or do you even fear feedback?&lt;/em&gt;”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/jpiscaer&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Joep&lt;/a&gt;’s talk started with an exercise to see if the people in the audience have some form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Impostor_syndrome&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Impostor Syndrome&lt;/a&gt; by asking several questions like the one mentioned above.
People had to raise their hand if the question applied to them and to keep them up during the next questions. 
At the end of his question round, more than half the audience had raised their hand.&lt;/p&gt;

&lt;p&gt;A collection of feelings of individual doubts that overwhelmed their successes and accomplishments which makes them think they are a ‘fraud’. 
He described Impostor syndrome as an internal measuring stick that is broken or Pluralistic ignorance. 
Doubting yourself privately, believing you are alone in thinking that way because no one voices their doubts. 
It is very likely that one or more of your colleagues have Impostor Syndrome although they will not admit they suffer from it. 
Some are more open about that topic than others. 
No matter how successful they are in their personal life and career, they ‘suffer’ Impostor Syndrome in some way or another. 
Mike Cannon-Brookes, CEO of one of the larges DevOps companies in the world is very open about it during his TED talk.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“&lt;em&gt;Other people feel like this, too. And apparently it doesn’t go away with more success.&lt;/em&gt;” - Mike Cannon-Brookes, Atlassian&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Atlassian started, like most big tech companies, from a garage. 
It grew bigger and bigger and at some point, they needed an HR-person. 
While Mike was interviewing his potential HR-person, he felt a bit unsure, because he has never worked in a company with an HR-person before. 
So how will he know if the potential HR-person has the right skills and attitude?&lt;/p&gt;

&lt;p&gt;Like with many things, there is always a beginning where you have to figure out what way is the right way to do things. 
There is mostly not &lt;em&gt;one&lt;/em&gt; best practice since everyone has their own. 
It is sometimes hard to know if your way is the right way, the good way or just bad. 
That will mostly lead to discussions and insecurity with people, because they don’t know or they are not really sure if their statement is well grounded.&lt;/p&gt;

&lt;p&gt;Especially technology can change rapidly over time. 
By the time you have learned a new thing it’s already obsolete.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Meme - Your Facts No Longer Apply&quot; src=&quot;/img/2020-03-31-devopsdays/your-facts-no-longer-apply.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Joep learned about Novell back when it was the latest and the greatest server Operating System you could have.
By the time Joep became a guru, it was already obsolete and surpassed by other Operating Systems.&lt;/p&gt;

&lt;p&gt;The tech landscape changes every couple of years and so sometime, you have to learn things again. 
That doesn’t really help when the &lt;a href=&quot;https://en.wikipedia.org/wiki/Dunning-Kruger_effect&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Dunning-Kruger&lt;/a&gt; effect applies when learning new stuff. 
Most people don’t really discuss that certain things are new to them and that they are not really good at it yet. 
They feel insecure sometimes because they are unsure or afraid that their idea or statement is incorrect or a best practice.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Dunning-Kruger Effect&quot; src=&quot;/img/2020-03-31-devopsdays/dunning-kruger-effect.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are certain things you can do to reduce the feeling of the Impostor Syndrome (or to recalibrate your ‘internal ruler’ so to speak).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Nothing compares to you.&lt;/strong&gt; &lt;br /&gt;
Every time you say something negative about yourself, say two things that are positive about yourself. 
It is as easy as that to retrain your internal NLP (Neuro Linguistic Programming) filter. 
At some point, your negative thoughts will diminish, and the positive ones will stay. 
Make sure to try this in front of a mirror!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I will not compare myself to strangers on the internet.&lt;/strong&gt; &lt;br /&gt;
You shouldn’t compare yourself to others, especially to people on the internet, because they are the worst.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Practice on giving compliments to others. And learn to receive them.&lt;/strong&gt; &lt;br /&gt;
They can come from different perspectives. 
For a kid it’s an accomplishment if he or she is able to tie his/her own shoelaces because it is new to him/her.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learn how others make stuff and let others learn from you.&lt;/strong&gt; &lt;br /&gt;
Other people, no matter how professional they are, make mistakes as well and can learn things from you and you can learn from them.
&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pair programming&lt;/li&gt;
  &lt;li&gt;Pair review&lt;/li&gt;
  &lt;li&gt;Celebrate your failure&lt;/li&gt;
  &lt;li&gt;Speak publicly&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Find something you’re passionate about and keep being tremendously interested in it.&lt;/strong&gt;&lt;br /&gt;
Like a hobby where you can screw things up without consequences.&lt;/p&gt;

&lt;h2 id=&quot;fight-flight-or-freeze--releasing-organizational-trauma-by-matty-stratton&quot;&gt;Fight, Flight or Freeze – Releasing Organizational Trauma, by Matty Stratton&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img class=&quot;p-image&quot; alt=&quot;Matty Stratton&quot; src=&quot;/img/2020-03-31-devopsdays/matt-stratton.jpg&quot; /&gt;&lt;/span&gt;
Imagine a zebra grazing in the savanna of the African wilderness when suddenly a predator goes after the zebra. 
Of course, the zebra will run for its life (the flee state). 
When the zebra is caught by the predator, it ‘freezes’ because the zebra’s nervous system is overwhelmed and it has no further solutions anymore, hoping the predator will drop him and go on. 
After the zebra has managed to get away, it literally shakes all his stress off and goes back to grazing like nothing happened. 
Humans can react the same way zebras do, although we are, of course, not a zebra. 
We humans on the other hand can experience traumas long after a dreadful situation has occurred.&lt;/p&gt;

&lt;p&gt;Animals are not traumatized by routine threats to their lives, where humans on the other hand, are really overwhelmed and often subject to traumatic symptoms of hyper arousal, shutdown and dysregulation, as Peter Levine’s calls it. 
During day two, &lt;a href=&quot;https://twitter.com/mattstratton&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Matty Stratton&lt;/a&gt;, DevOps advocate at PagerDuty, was talking about crisis management and traumatic events within organizations and teams based on his own experience with post-traumatic stress.&lt;/p&gt;

&lt;p&gt;Let’s start on how traumas can occur, although it’s rather complex to explain.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Traumas occur when one’s solutions (active response to threat) does not work. 
The case where your nervous system can’t handle it.
Traumas can result from both real or perceived threats. 
Even a perception of a ‘threat’ can also cause or recall traumatic situations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Trauma is subjective and relative. 
Everyone experiences and handles stress in a different way. 
People from the military, for example, experience stress and traumas in a different way than people in software projects. 
But that doesn’t mean that your experience isn’t real, even though the experience from a soldier is much worse.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But how does that apply to an organization? 
You can deal with common situations and everything will go back to normal. 
It’s always business as usual (the gray line in the normal range), but severe outages or a similar event, where the team’s capacity for a solution does not work, can lead to non-discharged stress (the red line).&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Dunning-Kruger Effect&quot; src=&quot;/img/2020-03-31-devopsdays/Symptoms-of-undischarged-traumatic-stress.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hyperarousal organizations are hyper-vigilant (like they are fighting Voldemort). 
They are hyper-aware of threats which causes a slowdown in moving forward. 
It’s not necessarily bad for an organization to be vigilant but it is bad when it loses a sane balance between vigilant and the will to move forward and innovate.&lt;/p&gt;

&lt;p&gt;Organizations can also be in a ‘freeze’ state when they believe that they are ‘immune’ to a standstill so they won’t make any changes on how they operate.&lt;/p&gt;

&lt;p&gt;Humans like pattern recognition. 
We see signals that might remind us of events that happened in the past and motivate us to respond the way we did last time. 
But the thing is that nothing is the same as it ever was back in the day as systems are becoming more complex as they grow.&lt;/p&gt;

&lt;p&gt;Today’s challenge is to make organizations more resilient against dreadful events. 
Resilient organizations are not traumatized by routine threats to their mission or business. 
Non-resilient organizations are readily overwhelmed and often subject to the symptoms of overreaction, shutdown and lack of regulated effort.&lt;/p&gt;

&lt;p&gt;What you can do to be more resilient is to learn from your mistakes. 
Organize game days where you can practice an incident or outage in a relax and safe way.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;DevOpsDays has a different but interesting format.
There are talks in the morning and lightning talks and open spaces during the afternoon/evening where you can bring your own topics that you want to discuss with others. 
What I also like is the fact that there’s a good variety between the amount of technical and soft-skills talks.&lt;/p&gt;

&lt;p&gt;The badges that DevOpsDays handed out were actually seed mats that you can plant afterwards (which I’ve done already)! 
UPDATE: Unfortunately nothing came out of it.
&lt;img alt=&quot;Conference badge&quot; src=&quot;/img/2020-03-31-devopsdays/badge.jpg&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Overall, it was a good and informative conference that I can recommend to anyone who is interested in DevOps and teamwork optimizations within organizations.&lt;/p&gt;

&lt;p&gt;More conference pictures can be found &lt;a href=&quot;https://photos.app.goo.gl/vm3oYVJUFt18uGbx8&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Johan&quot;, &quot;last_name&quot;=&gt;&quot;Silkens&quot;, &quot;permalink&quot;=&gt;&quot;/author/johan-silkens/&quot;, &quot;avatar&quot;=&gt;&quot;johan-silkens.jpg&quot;, &quot;title&quot;=&gt;&quot;Java Developer&quot;, &quot;linkedin&quot;=&gt;&quot;johan-silkens-848bb1b2&quot;, &quot;twitter&quot;=&gt;&quot;SilkensJ&quot;, &quot;email&quot;=&gt;&quot;johan.silkens@ordina.be&quot;, &quot;github&quot;=&gt;&quot;JSilkens&quot;, &quot;bio&quot;=&gt;&quot;Johan is a Java Developer at Ordina Belgium. He is passionate about technology and science since he was as kid and is always up for a challenge.&quot;}</name><email>johan.silkens@ordina.be</email></author><category term="Conference" /><category term="DevOps" /><category term="Conference" /><summary type="html">The 7th edition of DevOpsDays Amsterdam in ‘Pakhuis de Zwijger’ was my first experience with DevOpsDays. I’d like to share some talks and my impressions about the conference, because sharing ideas worth spreading is what we aim for at JWorks.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-03-31-devopsdays/devopsdays-amsterdam-2019.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-03-31-devopsdays/devopsdays-amsterdam-2019.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Managing the size of your shiny monorepo</title><link href="https://ordina-jworks.github.io/architecture/2020/03/31/nx-sparse-checkout.html" rel="alternate" type="text/html" title="Managing the size of your shiny monorepo" /><published>2020-03-31T00:00:00+00:00</published><updated>2020-03-31T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2020/03/31/nx-sparse-checkout</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2020/03/31/nx-sparse-checkout.html">&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;Using a monorepo has some great advantages, including no longer having to manage npm dependencies for each individual project and the ability to easily create libraries and reuse them between applications.
You can create libraries, for example about authentication, that each team in your organisation can include in their application and if an update should be needed to that library, the tooling you use can automatically build each (and only those) application that include that library.&lt;/p&gt;

&lt;p&gt;When talking about monorepo’s within frontend development communities, Nrwl’s Nx solution will certainly be mentioned.
It allows to create a workspace in which all your applications might exist together, using one single &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt;, no longer solely focused on Angular, but also React, simple web applications or NodeJS applications.
It also includes some useful tslint extensions and scripts to automate build steps using a dependency graph.&lt;/p&gt;

&lt;p&gt;But what happens when you have a lot of applications in your organisation?
Your IDE might start to work slower, its intellisense might get cluttered, or when searching for a specific file you receive a lot of results you don’t need for the application you’re working on.
This happens because there are just too many files in your repository.&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;p&gt;Git has a little-known (experimental) feature called sparse checkout.
From the &lt;a href=&quot;https://www.git-scm.com/docs/git-sparse-checkout&quot;&gt;git-scm.com&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Sparse checkout” allows populating the working directory sparsely.
It uses the skip-worktree bit (see git-update-index) to tell Git whether a file in the working directory is worth looking at.
If the skip-worktree bit is set, then the file is ignored in the working directory.
Git will not populate the contents of those files, which makes a sparse checkout helpful when working in a repository with many files, but only a few are important to the current user.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In short, it allows you to checkout only a part of the repository, and when committing, only those folders that are checked out will also be committed to.
It’s a bit like &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;, but local only.
It doesn’t affect the repository itself.&lt;/p&gt;

&lt;p&gt;The information for which files to checkout is stored in a file &lt;code class=&quot;highlighter-rouge&quot;&gt;$GIT_DIR/info/sparse-checkout&lt;/code&gt; and the contents have a similar syntax of the &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; file.
So using a line like &lt;code class=&quot;highlighter-rouge&quot;&gt;!/folder/my-folder-to-ignore&lt;/code&gt; would remove that folder from your working directory, while never affecting it on the remote repository.&lt;/p&gt;

&lt;p&gt;Now the idea is to remove those folders that are irrelevant to the project you’re working on by adding their paths to the &lt;code class=&quot;highlighter-rouge&quot;&gt;sparse-checkout&lt;/code&gt; file.
When a new checkout is performed, the changes in the file are applied and you would have a little less clutter in your workspace.&lt;/p&gt;

&lt;p&gt;If you want to know more details and some extra commands, read &lt;a href=&quot;https://github.blog/2020-01-17-bring-your-monorepo-down-to-size-with-sparse-checkout/&quot;&gt;this GitHub blog post&lt;/a&gt; from Derrick Stolee.&lt;/p&gt;

&lt;h2 id=&quot;the-tool&quot;&gt;The tool&lt;/h2&gt;

&lt;p&gt;Of course it’s always better to automate these things to reduce errors.
I developed a tool &lt;a href=&quot;https://www.npmjs.com/package/nx-sparse-checkout&quot;&gt;nx-sparse-checkout&lt;/a&gt;, which can be added to a workspace using Nx 8.11 and above.
I used the idea from &lt;a href=&quot;https://twitter.com/kwintenp&quot;&gt;KwintenP&lt;/a&gt;, updated it for use in Nx 8 and made some other enhancements to improve the user experience.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-03-31-nx-sparse-checkout/example.gif&quot; alt=&quot;Example of nx-sparse-checkout&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;The tool allows you to choose the projects you want to checkout (either comma-separated or interactive) and then uses Nx’s dependency graph to determine which projects your selection is depending on and adds those to the list of projects to checkout.
It then sets all projects that are not needed to be ignored using the &lt;code class=&quot;highlighter-rouge&quot;&gt;sparse-checkout&lt;/code&gt; file.
This way all other files (like &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;tsconfig.json&lt;/code&gt;, etc…) and other folders (like tools) are still available to you.
Resetting can be done by either selecting everything or passing the &lt;code class=&quot;highlighter-rouge&quot;&gt;--all&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;Using this technique, you have the advantages of a monorepo, while not having to deal with an enormous folder structure.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Orjan&quot;, &quot;last_name&quot;=&gt;&quot;De Smet&quot;, &quot;permalink&quot;=&gt;&quot;/author/orjan-de-smet&quot;, &quot;avatar&quot;=&gt;&quot;orjan-de-smet.jpg&quot;, &quot;title&quot;=&gt;&quot;Frontend Developer&quot;, &quot;email&quot;=&gt;&quot;orjan.desmet@ordina.be&quot;, &quot;twitter&quot;=&gt;&quot;orjandesmet&quot;, &quot;github&quot;=&gt;&quot;orjandesmet&quot;, &quot;bio&quot;=&gt;&quot;Orjan is a Frontend Developer at Ordina Belgium, keen on building structured quality applications with a focus on Reactive Programming and dealing with it. He is always interested to try new technologies and to share his experiences. In his spare time, he enjoys a good game or movie or dining out.&quot;}</name><email>orjan.desmet@ordina.be</email></author><category term="Architecture" /><category term="Monorepo" /><category term="Nx" /><category term="Git" /><summary type="html">The problem</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-03-31-nx-sparse-checkout/header.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-03-31-nx-sparse-checkout/header.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Healthcare on FHIR</title><link href="https://ordina-jworks.github.io/ehealth/2020/03/28/Healthcare-on-FHIR.html" rel="alternate" type="text/html" title="Healthcare on FHIR" /><published>2020-03-28T00:00:00+00:00</published><updated>2020-03-28T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/ehealth/2020/03/28/Healthcare-on-FHIR</id><content type="html" xml:base="https://ordina-jworks.github.io/ehealth/2020/03/28/Healthcare-on-FHIR.html">&lt;h1 id=&quot;and-then-there-was-fhir&quot;&gt;And then there was FHIR&lt;/h1&gt;
&lt;p&gt;The healthcare industry is currently buried under mountains of data, and much of it is unorganized or out of reach. For instance, care givers who are responsible for emergency care may not always have access to the patient’s history they need.
This might force them to resort to guessing or basing their treatment on the information the patient provides. If the patient is unable to give a medical history or other information such as allergies, the problem gets worse.&lt;/p&gt;

&lt;p&gt;Exchanging healthcare information in a safer and faster manner is therefore a primary goal in the healthcare industry.
Software developers and IT professionals in this industry are tasked with integrating software applications without sacrificing security of sensitive patient information.&lt;/p&gt;

&lt;p&gt;Today’s health IT environment is also very fragmented. 
Integrating with different health systems as well as sharing data is a difficult and expensive process.
Each of these systems tend to favor flexibility of their specific function or department over interoperability with external applications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fast Healthcare Interoperability Resources&lt;/strong&gt; (FHIR, pronounced “fire”) is a set of standards providing a mechanism for exchanging data between healthcare applications. 
It was first sponsored by &lt;a href=&quot;http://www.hl7.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Health Level Seven International (HL7)&lt;/a&gt; in 2011, and now incorporates the best features from previously developed standards.&lt;/p&gt;

&lt;p&gt;The introduction of the FHIR specification was driven by the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Patient-centric healthcare: the patient is in control of his own medical data therefore sharing data across organizations and disciplines becomes more important.&lt;/li&gt;
  &lt;li&gt;Shift from offline to online, from desktop to cloud and from desktop to tablet.
FHIR is based on the REST architectural style, thus being suitable for lightweight devices.&lt;/li&gt;
  &lt;li&gt;Data transparency becomes more and more important. 
FHIR acts as an ‘Open API’ to access data silos so systems can more easily collaborate with each other.&lt;/li&gt;
  &lt;li&gt;Data analytics is a hot topic and requires data transparency but also for the data itself to be in a format which is optimized for analysis.
Standardized and well-documented models as well as support for JSON-like formats by modern databases make FHIR an interesting choice.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The intended scope of FHIR is broad, covering human and veterinary, clinical care, public health, clinical trials, administration and financial aspects. The standard is intended for global use and in a wide variety of architectures and scenarios.”&lt;/p&gt;

  &lt;p&gt;&lt;em&gt;- HL7 (Health Level Seven International)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This relatively new protocol has several advantages:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The FHIR specification is free to use, open source with no restrictions and entirely available online at &lt;a href=&quot;https://www.hl7.org/fhir&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://www.hl7.org/fhir/&lt;/a&gt;.
It has been licensed under the Creative Commons Public Domain License, a license that permits the following: “You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission.”&lt;/li&gt;
  &lt;li&gt;It has a strong focus on fast and easy implementation by using common tools, formats and web-based technologies without a steep learning curve. 
Multiple implementation libraries are available with many examples to kickstart development.
For instance, the &lt;a href=&quot;https://hapifhir.io&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;HAPI FHIR library&lt;/a&gt; is an open source implementation of the HL7 FHIR specification for Java.&lt;/li&gt;
  &lt;li&gt;The FHIR format is human-readable.
Although it is not intended for direct human viewing, being directly understandable helps both implementers and medical personnel.
The base out-of-the-box interoperable resources can be used as is, but can also be extended and adapted for local or regional requirements.&lt;/li&gt;
  &lt;li&gt;FHIR leverages modern web-based communication technologies such as XML, JSON, HTTP, Atom, OAuth, …
It supports RESTful architectures, but other information exchange architectures/paradigms as well. The Document paradigm allows a system to send over a collection of resources about a Patient, for instance a referral to a specialist which involves the patient’s history including medications and diagnoses. FHIR also supports the Messaging paradigm which is often based on real-world events like a Patient being discharged from the hospital.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;why-should-you-be-excited-about-fhir&quot;&gt;Why should you be excited about FHIR?&lt;/h1&gt;
&lt;p&gt;FHIR has the potential to make healthcare much more similar to other internet-based experiences that consumers nowadays enjoy in different industries.&lt;br /&gt;
The Internet of Medical Things (IoMT) is a subset of IoT devices that captures and transmits patient-generated health data (PGHD). 
IoMT represents one of the largest technology revolutions and is growing at a lightning pace. 
The mountains of PGHD are growing every day but remain meaningless to healthcare providers if they’re not able to access the essence of the data quickly and easily. 
FHIR may be the glue between your electronic health record (EHR) on the one hand and your smart electric toothbrush, blood glucose monitor and fitness tracker on the other hand.
It allows connecting PGHD to streamlined healthcare provider workflows and filtering the bulk-load of data in a way that makes the data useful and actionable for your care provider.&lt;/p&gt;

&lt;p&gt;Patients who see multiple care providers in different health systems might no longer have to worry about having three or four patient portals from organizations using different EHRs.
One single personal health record, which integrates data from different formats, can deliver a comprehensive view of all medications, problems, and allergies.&lt;/p&gt;

&lt;p&gt;FHIR includes all aspects of healthcare-related interoperability through RESTful APIs and a common format for hundreds of clinical data models. This is useful for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;healthcare integrators: Transitioning to FHIR formatted XML/JSON objects in a RESTful architecture will enable you to have atomic data access to individual items within a resource, for example the Patient demographics or Observations for lab results.&lt;/li&gt;
  &lt;li&gt;healthcare systems: Building and running applications on this API standard will result in richer products with data connected from external systems.&lt;/li&gt;
  &lt;li&gt;patients: You can get and share your medical data in more ways than ever before, including with apps that you use.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;what-about-the-tech-giants&quot;&gt;What about the tech giants?&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Microsoft recently released &lt;a href=&quot;https://docs.microsoft.com/en-gb/azure/healthcare-apis/overview&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;FHIR server for Azure&lt;/a&gt;, an easy way to manage and persist health information in the cloud.
It allows you to create and deploy a FHIR service in minutes, and leverage the elastic scale of the cloud.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloud.google.com/healthcare&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Google Healthcare API&lt;/a&gt; bridges the gap between care systems and applications built on Google Cloud.
It supports the industry standard interoperability protocols such as HL7, DICOM, and of course FHIR.
Google lets its customers use this medical data for analytics and machine learning in the cloud which can unlock insights that lead to clinical improvements for patients.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.apple.com/healthcare/health-records/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apple’s Health Records app&lt;/a&gt; uses FHIR to let consumers download data from their health care providers in the U.S.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/comprehend/medical/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Amazon Comprehend Medical&lt;/a&gt; works through &lt;a href=&quot;https://aws.amazon.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Amazon Web Services&lt;/a&gt; and is a natural processing service that uses machine learning to extract relevant medical information from unstructured text and map it to FHIR resources.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-and-the-community&quot;&gt;… and the community?&lt;/h1&gt;
&lt;p&gt;A community is important for knowledge sharing and connecting experts to people and teams that need help. 
Luckily the FHIR specification has a strong community that helps connecting people for both giving and getting value:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lots of &lt;a href=&quot;https://wiki.hl7.org/Publicly_Available_FHIR_Servers_for_testing&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;public FHIR servers&lt;/a&gt; are available for testing.&lt;/li&gt;
  &lt;li&gt;FHIR developers participate actively on &lt;a href=&quot;https://stackoverflow.com/questions/tagged/hl7_fhir&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;StackOverflow&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.devdays.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;DevDays&lt;/a&gt; is the most important and largest FHIR-only event in the world.
The DevDays mission is to give health IT professionals around the the world the opportunity to learn about FHIR, to meet with colleagues and exchange ideas, and to apply what they have learned in their day-to-day work.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;what-does-fhir-look-like&quot;&gt;What does FHIR look like?&lt;/h1&gt;
&lt;p&gt;The following patient browser application gives an idea of what FHIR looks like and how easy it is to exchange data: &lt;a href=&quot;https://patient-browser.smarthealthit.org&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://patient-browser.smarthealthit.org&lt;/a&gt;. 
Definitely check out this demo app!&lt;/p&gt;

&lt;h2 id=&quot;fhir-resources&quot;&gt;FHIR Resources&lt;/h2&gt;
&lt;p&gt;A resource is the smallest unit of exchange with a defined behavior and meaning in interoperability, such as a Patient, a Device, an Observation, an Allergy Intolerance, … .
It has an identity and location (URI) where it can be found.
Furthermore, it is made up of elements of a particular datatype, and can be represented either as an XML document or a JSON document.&lt;/p&gt;

&lt;p&gt;An exhaustive list of FHIR base resources is described here: &lt;a href=&quot;http://www.hl7.org/implement/standards/fhir/resourcelist.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;http://www.hl7.org/implement/standards/fhir/resourcelist.html&lt;/a&gt;. 
The FHIR development team has adopted the 80% rule for resources: only define and include concepts applicable to 80% of normal implementations.
Adherence to the 80% rule is key to keeping the standard usable and not too overwhelming.
What about the other 20%? FHIR has a built-in extensibility capability for specific requirements of a particular region, discipline or organizational process.
To make extensions manageable, a set of requirements is defined that must be met as part of their use and definition.&lt;/p&gt;

&lt;p&gt;Each resource is annotated with a number or an N letter.
This is the FMM (FHIR Maturity Level) which goes from 0 to 5 and finally N (Normative).
&lt;em&gt;0&lt;/em&gt; means that the resource is still a draft.
&lt;em&gt;5&lt;/em&gt; means that it has been published in two formal publication release cycles and has been implemented in at least five independent production systems in more than one country.
A resource is &lt;em&gt;Normative&lt;/em&gt; when it is considered stable.
Other metadata also include a Security Category which represents the sensitivity level (i.e Anonymous, Business, Individual, Patient).
The Boundaries and Relationships metadata describe when to use it and which resources are related to or referenced from this one.&lt;/p&gt;

&lt;p&gt;Example of a Patient:&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-28-Healthcare-on-FHIR/resource-structure.png&quot; alt=&quot;FHIR Resource structure&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:70%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;FHIR Resource structure&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.hl7.org/fhir/patient.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;full specification&lt;/a&gt; can be found on the HL7 FHIR website.&lt;/p&gt;

&lt;h2 id=&quot;example-fhir-architectures&quot;&gt;Example FHIR architectures&lt;/h2&gt;
&lt;p&gt;Building your solution with FHIR does not change your development process nor does it enforce a specific architecture or technology stack. FHIR can be used in a lightweight or heavyweight client, in a monolith or a microservices architecture, in a push or pull-based design, …
In any case, you will still need to complete a project discovery phase, formulate a project vision and scope. You can continue to use your favorite agile practices, test driven development, CQRS and Event Sourcing, DevOps and Continuous Integration.&lt;/p&gt;

&lt;p&gt;The following section gives an example of 2 possible FHIR architectures.&lt;/p&gt;

&lt;h3 id=&quot;fhir-server-with-existing-back-end&quot;&gt;FHIR server with existing back-end&lt;/h3&gt;
&lt;p&gt;This is the most common scenario where you supply an interoperable FHIR API on top of an existing solution so it can be easily understood and consumed by clients.
This approach results largely in a mapping effort as the existing data model needs to be converted to FHIR resources.
It is possible to have a mix of both a FHIR and a proprietary API.
This can have several reasons like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the backend does not (yet) support the FHIR capabilities the client needs&lt;/li&gt;
  &lt;li&gt;the FHIR specification does not describe your healthcare domain or use case&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-28-Healthcare-on-FHIR/fhir-existing-backend.png&quot; alt=&quot;Mixed FHIR/Proprietary API with existing back-end&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Mixed FHIR/Proprietary API with existing back-end&lt;/p&gt;

&lt;h3 id=&quot;native-fhir-server-with-fhir-back-end&quot;&gt;Native FHIR server with FHIR back-end&lt;/h3&gt;
&lt;p&gt;This architecture is a FHIR-native solution because FHIR becomes the central design element of the system. 
FHIR is used as a platform specification that is stored directly in the SQL or NoSQL back-end data store and comes with some powerful features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a healthcare domain model (aka the Resources) and its extension capabilities&lt;/li&gt;
  &lt;li&gt;description of the types of search capabilities supported by a FHIR server&lt;/li&gt;
  &lt;li&gt;description for a FHIR server to advertise its capabilities to other systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-28-Healthcare-on-FHIR/fhir-fhir-backend.png&quot; alt=&quot;Native FHIR server with FHIR back-end&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Native FHIR server with FHIR back-end&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;
&lt;p&gt;Today, there’s lots of buzz about FHIR.
You might find it anywhere from federal agencies to major technology companies.
Google, Microsoft and Apple have all thrown in their considerable weight and cloud-based resources behind FHIR and are improving interoperability in healthcare.
The underlying concepts behind FHIR are important drivers of the push towards interoperability.
It supports the exchange of data between software applications in healthcare, combining the best features of HL7’s existing interoperability protocols while leveraging the latest web standards and applying a tight focus on implementability. 
FHIR is worth paying attention to because it is a huge step forward in working with healthcare data and is likely to have a significant impact on health IT.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Martin&quot;, &quot;last_name&quot;=&gt;&quot;Kwee&quot;, &quot;permalink&quot;=&gt;&quot;/author/martin-kwee/&quot;, &quot;avatar&quot;=&gt;&quot;martin-kwee.jpg&quot;, &quot;title&quot;=&gt;&quot;Principal Consultant&quot;, &quot;email&quot;=&gt;&quot;martin.kwee@ordina.be&quot;, &quot;linkedin&quot;=&gt;&quot;martinkwee&quot;, &quot;bio&quot;=&gt;&quot;Martin is a Java consultant at Ordina Belgium. He enjoys a good technical challenge and has a strong interest in architecture and eHealth.&quot;}</name><email>martin.kwee@ordina.be</email></author><category term="eHealth" /><category term="eHealth" /><category term="Architecture" /><category term="FHIR" /><category term="Interoperability" /><summary type="html">And then there was FHIR The healthcare industry is currently buried under mountains of data, and much of it is unorganized or out of reach. For instance, care givers who are responsible for emergency care may not always have access to the patient’s history they need. This might force them to resort to guessing or basing their treatment on the information the patient provides. If the patient is unable to give a medical history or other information such as allergies, the problem gets worse.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-03-28-Healthcare-on-FHIR/FHIR_logo.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-03-28-Healthcare-on-FHIR/FHIR_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Charting the Non-Functional Waters</title><link href="https://ordina-jworks.github.io/architecture/2020/03/24/Charting-non-functionals.html" rel="alternate" type="text/html" title="Charting the Non-Functional Waters" /><published>2020-03-24T00:00:00+00:00</published><updated>2020-03-24T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2020/03/24/Charting-non-functionals</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2020/03/24/Charting-non-functionals.html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Where functional requirements are relatable to most stakeholders as they are derived from their areas of expertise, specifying the brunt of the non-functionals tends to fall to the solution architect. 
As these requirements are more technical in nature, the affinity of other stakeholders with them is not as pronounced. 
When inquiring about their relevance, the typical answer will be in very generic fashion, for example: “The application needs to be fast.” 
Trying to get more concrete and measurable statements is not an easy endeavor. 
We’ll get back to this further on in the blog post.&lt;/p&gt;

&lt;h1 id=&quot;formalizing-the-requirements&quot;&gt;Formalizing the Requirements&lt;/h1&gt;

&lt;p&gt;Once we have the appropriate numbers, we need to formalize them and get them validated. 
Just as the structure and formalization of the functional requirements is expressed as user stories, or in some cases even more detailed in the form of Business Processes and use cases, in a similar manner will we structure and formalize the non-functionals based on the ISO 25010 standard. 
Some older architecture documents could also still make a reference to the ISO 9126 standard, which is its predecessor.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-24-Charting-non-functionals/iso25010.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;ISO 25010 Standard&lt;/p&gt;

&lt;p&gt;Since the ISO standard focuses on quality and acceptance of the delivered product, the same model should be the basis to compose requirements as well. 
As a result, the quality attributes can be considered as the non-functional requirements of the product focusing on expectations about functionality, usability, reliability, efficiency, maintainability and portability. 
However, in order to make the factors more complete and representative, each of the characteristics has been split up into its proper set of sub-characteristics.&lt;/p&gt;

&lt;h1 id=&quot;prioritizing-the-requirements&quot;&gt;Prioritizing the Requirements&lt;/h1&gt;

&lt;p&gt;Note however that not all characteristics and associated sub-characteristics are as important to each and every project. 
On a case-by-case basis, some of them can be given a very low priority or even entirely neglected. 
Hence, the priority indication is very important in the specification for every requirement. 
These are the tradeoffs that an architect needs to chart to arrive at the proper solution. 
One of the ways to weigh them was described in the &lt;a href=&quot;https://www.amazon.co.uk/Software-Requirements-Developer-Best-Practices/dp/0735679665/ref=sr_1_1&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;book “Software Requirements” by Karl Wiegers and Joy Beatty&lt;/a&gt;. 
The idea is to chart them in a matrix which marks the requirements that take precedence over others when they have conflicting impacts on the solution. 
For example: When business stakeholders ask for a speed of delivery that is contradicted by security concerns demanding a mandatory waiting period for customer due diligence purposes, a decision needs to be taken on which of these requirements gets the upper hand for the implementation.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-24-Charting-non-functionals/nonfuncprios.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A reflection of this type of requirements contradiction can be found in the CAP theorem. 
The CAP theorem, also named Brewer’s theorem after computer scientist Eric Brewer, states that it is impossible for a distributed computer system to simultaneously provide more than two out of three of the following guarantees: Consistency. Availability. Partition tolerance. 
Consistency is the characteristic that determines that a service will always give the same answer across multiple nodes. 
Availability reflects that every service request should get a response. Partition tolerance is the ability to handle the occasional failure in communication between two services. 
A balance matching the needs of the solution must be determined between these three requirements in order to implement a solution that fits the bill.&lt;/p&gt;

&lt;p&gt;There are some frameworks that already have some form of priority already built in. They implement this by reducing the number of non-functional categories to only those relevant in their point of view. For example, when we take the AWS Well-Architected Framework, the determining non-functionals are reduced to five categories based on Amazon’s experiences and best practices. For each of these pillars AWS has published a white paper on how to improve and optimize them. IT also provides tooling and labs to help the architect make the proper tradeoffs.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-24-Charting-non-functionals/awswellarch.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Pillars of the AWS Well-Architected Framework&lt;/p&gt;

&lt;p&gt;When maturing the requirement list set out for the solution, it might become a difficult and complex task to get accurate numbers to quantify the requirements and make them measurable. We can gather the logs of existing systems that we are replacing to get a grip on what traffic we can expect. But this is not always an option. Suppose we are developing a solution for registering timesheets of employees in a small business that have just gotten a significant enough growth in its sales to justify the cost of such a solution. It doesn’t have numbers on how many times the services of such a system should be called and it doesn’t have an existing system from which to extract them. This is where we start to rely on deduction. We start from relevant data that we do have access to or make assumptions based on experience and we extrapolate from there. In the case of our timesheet solution, we count the number of employees (relevant data) and multiply it by the number of times a week we assume they will access the timesheet solution resulting in a quantified requirement.&lt;/p&gt;

&lt;h1 id=&quot;data-solution-requirements&quot;&gt;Data Solution Requirements&lt;/h1&gt;

&lt;p&gt;Most of the requirements stipulated by the ISO 25010 standard apply to software solutions. The game changes a bit if this solution is primarily or even solely focused on the data facet. When designing a data solution such as for example a solution that gathers and evaluates the available data for a specific topic, we look at a sister standard of the one previously mentioned. The ISO 25012 is part of the same family and offers requirements fitting two categories with some these shared by both. These categories are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Inherent Data Quality: This category gathers all requirements that deal with the inherent data quality of the data sets that are being used in the solution.&lt;/li&gt;
  &lt;li&gt;System-Dependent Data Quality: This category deals with the requirements that have to do with the capabilities of maintaining the quality inherent in the data sets.&lt;/li&gt;
&lt;/ul&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-24-Charting-non-functionals/iso25012.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;ISO 25012 Standard&lt;/p&gt;

&lt;h1 id=&quot;operational-requirements&quot;&gt;Operational Requirements&lt;/h1&gt;

&lt;p&gt;When a solution finally goes live, it will have an impact on the existing way of working within the organization. 
Not only are its users a stakeholder, but there is also the team that will support the solution to consider as well. 
Therefore, a set of operational requirements is usually determined by analyzing how the managed services team will keep the solution up and running, how they will cope with bug fixing and evolutionary maintenance, and how to cope with negative impact.&lt;/p&gt;

&lt;p&gt;As with non-functional requirements, so can these requirements be categorized by using an ISO standard, in this case the ISO 25022 standard, or the “Quality in Use” Model. 
This standard defines measures for the characteristics of the previously mentioned ISO 25010 standard and consists of a basic set of impact measures and methodologies to quantify each of them. 
This standard is a collection of suggested measures and is by no means an exhaustive list. A visual representation of these requirements can be seen in the illustration below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-03-24-Charting-non-functionals/iso25022.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;ISO 25022 Standard&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In summary, an architect needs to be able to get a handle on all the angles of the solution as soon as possible in the development process, and requirements, both functional and non-functional, allow him or her the overarching vision to guide development along. 
Be wary of analysis paralysis though. 
To quote the former US Secretary of Defence Donald Rumsfeld: “There are known unknowns, that is to say, there are things that we now know we don’t know them.” 
So, avoid trying to get the perfect picture of the requirements, and instead factor into your solution that new requirements can pop up and hidden ones can be revealed during the later stages of the project.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Peter&quot;, &quot;last_name&quot;=&gt;&quot;De Kinder&quot;, &quot;github&quot;=&gt;&quot;peterdekinder&quot;, &quot;linkedin&quot;=&gt;&quot;peterdekinder&quot;, &quot;permalink&quot;=&gt;&quot;/author/peterdekinder/&quot;, &quot;avatar&quot;=&gt;&quot;peterdekinder.jpg&quot;, &quot;title&quot;=&gt;&quot;Solution Architect&quot;, &quot;email&quot;=&gt;&quot;peter.dekinder@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Peter is a Solution Architect with firm roots in the Java technosphere, but with a wide interest in all things architecture. His areas of specialization include Service Oriented Architectures, Business Process Management and Security.&quot;}</name><email>peter.dekinder@ordina.be</email></author><category term="Architecture" /><category term="Architecture" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-03-24-Charting-non-functionals/nonfunc_background.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-03-24-Charting-non-functionals/nonfunc_background.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Zero Plastic Rivers - explained</title><link href="https://ordina-jworks.github.io/cloud/2020/03/16/ZPR-explained.html" rel="alternate" type="text/html" title="Zero Plastic Rivers - explained" /><published>2020-03-16T00:00:00+00:00</published><updated>2020-03-16T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/cloud/2020/03/16/ZPR-explained</id><content type="html" xml:base="https://ordina-jworks.github.io/cloud/2020/03/16/ZPR-explained.html">&lt;h1 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#architecture&quot;&gt;Architecture&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#security&quot;&gt;Security&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#developer-experience&quot;&gt;Developer experience&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;As a society we treat plastic irresponsibly. Because of us, enormous amounts of plastic waste end up in our rivers.&lt;br /&gt;
And if we don’t remove this plastic from the rivers before it reaches the estuary, this plastic will inevitably end up in the plastic soup, which in turn gets bigger.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zeroplasticrivers.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;The Zero Plastic Rivers (ZPR) initiative&lt;/a&gt;  tries to solve this problem by doing three things: measure, prevent and clean up.&lt;br /&gt;
Plastic pollutes our seas and oceans.&lt;br /&gt;
Currently at least 150 million tons of plastic waste floats in our oceans, forming the infamous plastic soup.&lt;br /&gt;
And it is getting worse; it’s estimated another 8 million tons is added every year.&lt;br /&gt;
That’s about one truck of plastic per minute that get’s dumped into our oceans.&lt;/p&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;The Zero Plastic Rivers initiative&lt;/strong&gt;  wants to make sure that our rivers no longer bring plastic waste to the seas.&lt;br /&gt;
We want to do this based on a scientific and structured approach, inspired by the principles of quantitative optimization as defined by &lt;strong&gt;Six Sigma.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;endgoal&quot;&gt;Endgoal&lt;/h2&gt;
&lt;p&gt;Our rivers are severely polluted with plastic, making them the largest source of plastic soup in our oceans, even up to 80%.&lt;br /&gt;
We can only solve this problem by ensuring that our rivers no longer supply plastic to the sea.&lt;br /&gt;
And that is why we are striving for Zero Plastic Rivers.&lt;/p&gt;

&lt;p&gt;To be more effective in the fight against the plastic soup it is important to get more insight in how plastic moves through the rivers.&lt;br /&gt;
This is where Bert Teunkens together with the University of Antwerp comes into play.&lt;br /&gt;
The subject of his PhD is: Quantification and characterization of the plastic fluxes in the Scheldt basin, with the ultimate goal of setting-up an efficient remediation.&lt;/p&gt;

&lt;p&gt;To help him reach his goal of creating strategies to combat the plastic pollution he needs insights in how different kinds of plastic moves through our waterways.&lt;br /&gt;
Bert came up with different ways to gather this data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;using citizen science&lt;/li&gt;
  &lt;li&gt;IoT&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;citizen-science&quot;&gt;Citizen science&lt;/h3&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers Plastic&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_allplastic.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;A large quantity of plastic objects were dipped in fluorescent paint and were tagged with water resistant stickers containing metadata about that object.&lt;br /&gt;
These objects were released in the waterways with the assumption they would wash ashore eventually.&lt;br /&gt;
Because they were brightly colored, they would be easy to spot by passers-by.&lt;br /&gt;
These people could then enter various information about the object such as the unique object identifier, GPS location, pictures, description, …&lt;/p&gt;

&lt;h3 id=&quot;iot&quot;&gt;IoT&lt;/h3&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers Sensor&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_tracker.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Another great way to gather datapoints was through GPS trackers.&lt;br /&gt;
Various industrial grade battery powered GPS trackers were put in a waterproof casing and then deployed into the river.&lt;br /&gt;
Using a 2G network, these GPS trackers would travel along the river and transmit a new GPS fix every hour.&lt;br /&gt;
Various measures were taken to optimize battery consumption as we expected the trackers to travel for an extended period of time. This was done by putting a specific configuration on these devices.&lt;/p&gt;

&lt;h2 id=&quot;partnering&quot;&gt;Partnering&lt;/h2&gt;
&lt;p&gt;Bert approached Ordina because of our deep IoT knowledge and user centric end-to-end project approach.&lt;/p&gt;

&lt;p&gt;Ordina helped create an application to gather the datapoints and visualise them so that he could formulate ways of setting up efficient remediation.&lt;/p&gt;

&lt;p&gt;This was quite an exciting and important project for Ordina and the JWorks crew as it checks 2 boxes at the same time: doing a project with the latest and greatest technology while having a significant impact on society!&lt;/p&gt;

&lt;p&gt;This project would allow us to use all our skills to build a solution that would solve a major problem for society.&lt;br /&gt;
With our multi-disciplinary team we were able to tackle following domains: user experience, application and cloud architecture, frontend and backend development, security and managed application hosting.&lt;/p&gt;

&lt;h1 id=&quot;user-experience&quot;&gt;User Experience&lt;/h1&gt;
&lt;p&gt;From the get-go it seemed very crucial to nail the user experience for the citizen science part of the application.&lt;br /&gt;
The success of the project depended on benevolent strangers to pick up our brightly colored plastic waste, read the instruction and input a significant amount of data into our system.&lt;br /&gt;
This process needed to be clear, painless and concise. &lt;br /&gt;
Bad user interaction would lead to no datapoints and thus doom the project.&lt;/p&gt;

&lt;p&gt;The initial idea was to put QR tags on all the plastic objects and have users scan them.&lt;br /&gt;
Altough everyone deemed this an elegant and efficient way of working, we decided to test this on “regular people”.&lt;br /&gt;
This was done by conducting guerilla testing: talking to random people outside our office building, showing them a ZPR plastic object with a tag and seeing what they would do.&lt;/p&gt;

&lt;p&gt;Turns out very few people instinctively know what to do with a QR code.&lt;br /&gt;
To counter this, we opted to add a very short url on the object: www.zpr.one&lt;br /&gt;
This allowed more users to reach our application and fill in all the data we needed.&lt;/p&gt;

&lt;p&gt;Once they were in the application we had to make it straightforward for them to collect all the data we needed.&lt;br /&gt;
Various rapid iteration of the UI were made using wireframes and mockups.&lt;br /&gt;
These were tested and validated to create an optimal flow through the various screens as we wanted a very low threshold for users to input the data.&lt;/p&gt;

&lt;p&gt;We opted to create a Progressive Web Application (PWA) instead of a native application as we felt that users did not want to install yet another app.
As we required access to native features such as GPS and camera a PWA seemed perfect for the job!&lt;/p&gt;

&lt;h1 id=&quot;architecture&quot;&gt;Architecture&lt;/h1&gt;

&lt;p&gt;To build and run this modern and complex project we opted to use the AWS platform.&lt;br /&gt;
For a considerable amount of time we at JWorks have been investing our efforts and resources to build up our AWS portfolio.&lt;br /&gt;
This means we work on building up the AWS skills of our people and in parallel we work on building up our portfolio of AWS enabled solutions.&lt;br /&gt;
We have worked out several reference architectures that we prefer to use now.&lt;br /&gt;
The advantage of these architectures is that every consultant within our unit knows how to use them and develop applications using them.&lt;/p&gt;

&lt;p&gt;The Zero Plastic Rivers project proved to be an excellent opportunity to put some of these into practice.&lt;br /&gt;
You can view the architecture we opted to build in the following picture.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_architecture.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;This big architectural picture can be divided in 3 big sections:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Backend java application&lt;/li&gt;
  &lt;li&gt;Frontend ionic app&lt;/li&gt;
  &lt;li&gt;IoT sensor data ingestion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will highlight some key features of each architectural section in the following paragraphs.&lt;/p&gt;

&lt;h2 id=&quot;backend-application&quot;&gt;Backend application&lt;/h2&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_arch_backend.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;the-backend-itself&quot;&gt;The backend itself&lt;/h3&gt;
&lt;p&gt;Since we are called JWorks and we mainly focus on Java/Javacript development it should be no surprise that our backend application is written in Java with the Spring Boot framework.&lt;br /&gt;
In general we prefer to write backends in the microservices paradigm, but in this case the backend was sufficiently small that it only consists of 1 microservice.&lt;br /&gt;
The application itself is a pretty standard spring boot application.&lt;br /&gt;
We use a postgreSQL server hosted in RDS as our persistent datastore on the backend, supplemented with an elasticache Redis cluster to cache database queries and configurations for the IoT sensors used in the IoT sensor data ingestion part.&lt;br /&gt;
Our backend service is reachable over a REST interface for the outside world, we will talk more about this interface when we discuss the frontend application.&lt;/p&gt;

&lt;h3 id=&quot;hosting-of-the-application&quot;&gt;Hosting of the application&lt;/h3&gt;
&lt;p&gt;The backend application is hosted on our Kubernetes cluster in the AWS cloud. This cluster is an EKS cluster that we use to run several projects for customers and is also used for some of our internal applications.&lt;br /&gt;
The EKS cluster is a multi-worker node cluster setup with multiple Auto Scaling Groups so we can guarantuee almost 100% uptime on our applications that run on this cluster.&lt;br /&gt;
We have been using Kubernetes in different forms (on-premise, AKS, PKS,  …) for a long time now which means we have a very clear image of how to use it and how to run applications on a cluster.&lt;br /&gt;
We make heavy use of several key features like: secrets, configmaps, …&lt;br /&gt;
Our EKS cluster is running several plugins that allow us to quickly configure infrastructure components on the AWS cloud from within our cluster.&lt;br /&gt;
For example the REST interface of the application is exposed through a Kubernetes ingress which is hooked up to the ALB controller plugin.&lt;br /&gt;
This means that whenever we create a new ingress a new Application Load Balancer will be automatically provisioned in the AWS cloud to expose our deployment to the outside world. This makes it very easy to work with and allows us a lot of flexibility.&lt;/p&gt;

&lt;h2 id=&quot;frontend&quot;&gt;Frontend&lt;/h2&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_arch_frontend.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Our frontend application consists of two parts.&lt;br /&gt;
The first part is aimed at citizens who wish to help the cause. They can feed data in the system via the citizen science application when they find a bottle as shown in the image below.&lt;br /&gt;
This is the first way that data from the plastic bottles comes into our system. We allow the user to upload an optional image when submitting this data. These images are stored in a secure S3 bucket.&lt;br /&gt;
The second part is aimed at the researchers, and could be seen as the backoffice of the project, where the data given by the GPS trackers and the citizens is visualized in a clear and orderly way.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr-frontend-application.png&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;To develop this application we have chosen to use Ionic. &lt;a href=&quot;https://ionicframework.com/&quot;&gt;Ionic&lt;/a&gt; is a free-to-use web-based framework that allows you to build hybrid mobile apps for iOS and Android, all from one codebase. In other words, Ionic is a tool for cross-platform mobile development. Ionic enables you to develop mobile apps using web technologies and languages like HTML, CSS, JavaScript, Angular, and TypeScript.&lt;/p&gt;

&lt;h3 id=&quot;data-visualization&quot;&gt;Data visualization&lt;/h3&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_arch_data_ingestion.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;One of the most relevant components in this application is the map where the sensors and the plastic bottles in the river are visualized by means of the coordinates registered in these items as shown in the image above. For this we have chosen to use &lt;a href=&quot;https://leafletjs.com/&quot;&gt;Leaflet&lt;/a&gt; which is an open source JavaScript library for adding interactivity to maps. They have a ton of features and plugins to support doing pretty much anything with a map that you can think of.&lt;/p&gt;

&lt;p&gt;Ionic offers a wide variety of ready to use plug-ins and one of them is the camera that enables users who decide to participate in this project to take pictures of the bottles to update the status and deterioration of each bottle in the river.&lt;/p&gt;

&lt;h3 id=&quot;frontend-testing&quot;&gt;Frontend Testing&lt;/h3&gt;

&lt;p&gt;In reference to software testing we have mainly used Unit Testing to reduce the number of errors that are released during deployment, which we consider critical for effective software development.&lt;/p&gt;

&lt;h3 id=&quot;frontend-deployment&quot;&gt;Frontend deployment&lt;/h3&gt;

&lt;p&gt;Originally we planned to host this application in a nginx webserver in our EKS cluster. We changed to S3 as it is an easier to maintain solution than running your own webserver on Kubernetes. We have setup a hosted zone in Route53 which serves as the entry point of users into our application. Route53 then forwards users who visit zpr.one to our Cloudfront distribution. Cloudfront serves the ionic app from our S3 bucket which has static webhosting enabled. This setup seems optimal as it is low maintenance, tightly secured and highly scalable.&lt;/p&gt;

&lt;h4 id=&quot;low-maintenance&quot;&gt;Low maintenance&lt;/h4&gt;
&lt;p&gt;To explain why this setup is low maintenance let us take a look at the components used in this architecture.&lt;br /&gt;
We are making use of Cloudfront, S3 and Route53 in this setup.&lt;br /&gt;
All of these services are managed services provided by AWS.&lt;br /&gt;
This means that there is no maintenance required on our part as AWS guarantees uptime and makes sure that everything is running smoothly.&lt;br /&gt;
The only manual actions that have occurred on our side in this setup so far was to clear the Cloudfront cache after releasing a new version to have the new version more quickly available to users of the app.&lt;/p&gt;

&lt;h4 id=&quot;tightly-secured&quot;&gt;Tightly secured&lt;/h4&gt;
&lt;p&gt;Since we are using only managed services from AWS the burden of patching those services and making sure they are secured is on AWS itself.&lt;br /&gt;
AWS has an excellent reputation on this regard so we feel very comfortable in this regard.&lt;br /&gt;
We also make use of several additional features provided by AWS to secure our application further.&lt;br /&gt;
For example the S3 bucket that is used to host the website is only accessible through the Cloudfront distribution.&lt;br /&gt;
So users do not need access to the S3 resources itself, we implemented this nicely through Bucket policies and IAM access control.&lt;/p&gt;

&lt;h4 id=&quot;highly-scalable&quot;&gt;Highly scalable&lt;/h4&gt;
&lt;p&gt;Since we are only allowing traffic to our application from the Cloudfront distribution this means that we get all the benefits from this global CDN.&lt;br /&gt;
Cloudfront operates on the AWS edge locations which are spread throughout the world.&lt;br /&gt;
Because our application is mostly Belgium based this was not as important to us but the fact that Cloudfront routes its requests over the internal AWS backbone makes a huge difference in speed which is a nice feature if you are working with global applications.&lt;br /&gt;
The S3 service which acts as the origin for our Cloudfront distribution is &lt;strong&gt;nearly infinitely scalable&lt;/strong&gt; as proclaimed by AWS itself.&lt;br /&gt;
The interaction between our frontend and backend happens over REST services provided by our backend in the EKS cluster which is exposed over an ALB so we are very confident that we can scale up as needed.&lt;/p&gt;

&lt;h2 id=&quot;iot-sensor-data-ingestion&quot;&gt;IoT sensor data ingestion&lt;/h2&gt;

&lt;p&gt;IoT is all about processing a large quantity of messages.&lt;/p&gt;

&lt;p&gt;What makes IoT data challenging from a developer perspective is threefold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Protocol&lt;/li&gt;
  &lt;li&gt;Data format&lt;/li&gt;
  &lt;li&gt;Message Content&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Imagine you have a device that captures and delivers GPS data. 
Seems simple enough right? Guess again!&lt;/p&gt;

&lt;p&gt;A hardware vendor can decide to mix and match these 3 components.&lt;/p&gt;

&lt;p&gt;The vendor can those over which protocol he wants to send the data.
Some examples are: HTTP(S), TCP, UDP, MQTT, COAP, …&lt;/p&gt;

&lt;p&gt;He can also use different kinds of data-serialization formats to get the information across the network of choice: JSON, XML, Hex, Binary, something proprietary, … Different kinds of parsers will be needed.&lt;/p&gt;

&lt;p&gt;And last but not least: he can organise the way a message is structured. He can name fields any way he wants and use any kind of data type. Imagine two vendors reporting battery capacity. One could report it by sending a field called “battery” and reporting battery voltage.
Another could use a field called “power” and return a battery fill level percentage.&lt;/p&gt;

&lt;p&gt;Soon, it can become quite complex due to the number of combinations possible.&lt;/p&gt;

&lt;p&gt;Some of our plastic containers send their location via the 2G cellular network at regular intervals.&lt;br /&gt;
These messages reach us via a public network through the tcp protocol.&lt;/p&gt;

&lt;p&gt;As various protocols such as TCP and UDP are quite prevalent in IoT solutions, we do see that they are not yet first class citizens in the cloud.
Eventhough it is possible to modify the ingress to kubernetes on our NGINX to allow TCP data to pass through, this is not a scalable solution. Imagine having thousands upon thousands of devices starting new TCP connections. This would kill our NGINX.
To solve this problem we used a native AWS component: the network load balancer. 
This allowed limitless scaling of TCP connections. These TCP connections would then end up on an Spring Boot application hosted on AWS Beanstalk, which is basically a managed horizontally scalable Tomcat server. This application has to handle the interactions with the devices and acts as a “sensor gateway”.
The sensors can receive instructions and updates, but this has to happen inside the same open tcp connection within a very short timeframe.&lt;br /&gt;
This gateway consults the Elasticache for any needed instructions or updates.&lt;br /&gt;
If a return message is needed, it is sent through the open tcp connection.&lt;br /&gt;
The sensor detection message is then passed on to an SQS queue. From here on out, the focus of handling the message is less time-sensitive.&lt;br /&gt;
A Lambda function decodes the message on the queue and then pushes it to another SQS message queue.&lt;br /&gt;
A Spring Boot backend that is deployed in our kubernetes cluster handles these last events and persists them to our database.&lt;/p&gt;

&lt;h1 id=&quot;security&quot;&gt;Security&lt;/h1&gt;

&lt;p&gt;One key element of the security is controlling who has access to an application. To strengthen security, reduce risk and improve compliance, it is essential that only authorized users get to access specific data in an application and that authentication is required before that access is granted. This means that authentication is a critical component for most applications and in this project it was no exception, as we needed to secure the data visualization part of the application so that only researchers have access to advanced functionality.&lt;/p&gt;

&lt;p&gt;To perform this authentication, we have chosen to use AWS Cognito as it dramatically simplifies application development by providing an authentication service that is simple to integrate into any modern application. In addition to storing login information, Cognito can store standard and custom user account settings. Learn more about AWS Cognito and its advantages &lt;a href=&quot;https://aws.amazon.com/cognito/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another advantage of AWS Cognito is that it supports OpenID Connect which is a simple identity layer built on top of the OAuth 2.0 protocol, which allows clients to verify the identity of an end user based on the authentication performed by an authorization server or identity provider (IdP), as well as to obtain basic profile information about the end user in an interoperable and REST-like manner. Learn more about OpenID Connect &lt;a href=&quot;https://openid.net/connect/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;aws-cognito-and-openid-connect&quot;&gt;AWS Cognito and OpenID Connect&lt;/h3&gt;

&lt;p&gt;To carry out authentication using the OpenID Connect standard with Cognito we have chosen to use the Authorization Code Grant which is the preferred and most secure method for authorizing end users. Instead of directly providing user pool tokens to an end user upon authentication, an authorization code is provided. This code is then sent to a custom application that can exchange it for the desired tokens. Because the tokens are never exposed directly to an end user, they are less likely to become compromised.&lt;/p&gt;

&lt;p&gt;The image below illustrates the flow, and, in this &lt;a href=&quot;https://aws.amazon.com/blogs/mobile/understanding-amazon-cognito-user-pool-oauth-2-0-grants/&quot;&gt;blogpost&lt;/a&gt;, you can find more information about this approach.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;Authorization Code Grant Diagram&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_aws_cognito.jpg&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To secure our frontend we have used Manfred Steyer’s &lt;a href=&quot;https://github.com/manfredsteyer/angular-oauth2-oidc&quot;&gt;Angular-oauth2-oidc&lt;/a&gt; library but you could use any library as long as it is &lt;a href=&quot;https://openid.net/certification/&quot;&gt;OpenID certified&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Our colleague Jeroen wrote a fantastic &lt;a href=&quot;https://ordina-jworks.github.io/security/2019/08/22/Securing-Web-Applications-With-Keycloak.html#setting-up-the-front-end-and-back-end-applications&quot;&gt;blogpost&lt;/a&gt; that was very helpful to us. Jeroen shows the necessary steps to follow to secure any web application using OpenID Connect.&lt;/p&gt;

&lt;h1 id=&quot;d-day&quot;&gt;D-Day&lt;/h1&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers release&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_release.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers trail&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_plastictrail.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img alt=&quot;Zero Plastic Rivers trail2&quot; src=&quot;/img/2020-03-16-ZPR-explained/zpr_plastictrail2.jpg&quot; width=&quot;auto&quot; height=&quot;40%&quot; target=&quot;_blank&quot; class=&quot;image fit&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Tuesday December 17th was D-day. That day the bottles and sensors were finally thrown into the water. We had a tight timing because the bottles had to be thrown in the Scheldt river at high tide, at 3 different locations. 
It was a nice dry day and our client was quite nervous. Are all the signals coming in properly, is the sensor packed waterproof, …?  Especially because we were not able to test all that much with the sensors due to the tight timing. 
At high tide, it was time to throw the bottles in the water and register the sensor via our Ionic App. Everything runs smoothly and the signals from the sensors come in. You see the customer cheer up and leave satisfied to the next location. Everything goes as planned all day long and after just a few days the first users start registering the objects on our website.
And today, so many weeks later, we still receive new registrations. 
It was a nice ending of a fascinating and instructive project.&lt;/p&gt;

&lt;h1 id=&quot;developer-experience&quot;&gt;Developer-experience&lt;/h1&gt;

&lt;p&gt;For some developers on the team, Zero Plastic Rivers was the first experience with AWS and even their first cloud project.&lt;br /&gt;
In the beginning it was quite intimidating because a lot of different technologies of AWS were used.&lt;br /&gt;
But soon it turned out to be quite easy to configure and with some help from other colleagues (thanks guys) I got everything up and running pretty quickly.&lt;br /&gt;
In the beginning I was quite sceptical about the use of lambdas in our application, I didn’t immediately see the advantage of it but in the end it turned out to be the best option, especially if we want to build applications with many more sensors in the future. Although it was sometimes difficult to find the correct documentation.&lt;br /&gt;
My favorite technology was definitely Cognito. In a few lines of code you have a user administration of an entire application without having to worry about possible security holes.&lt;br /&gt;
In the end it was a very pleasant experience to get started with AWS.
Due to this eye-opening experience several developers are looking forward to becoming AWS certified and gaining a deeper and more complete AWS skillset.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;All in all we were very pleased with how we delivered this project. As this project was fully staffed with an Ordina High Performance Team, we were able to do everything by the book. We used the best methodologies for software delivery coupled with our preferred technology stack to build a true cloud native application.
We embraced the devops mindset: you build it, you run it.
Next to that we also embraced the agile mindset: respect, collaboration, improvement and learning cycles, pride in ownership, focus on delivering value, and the ability to adapt to change.&lt;/p&gt;

&lt;p&gt;We had a great team dynamic: experienced developers coaching and mentoring younger colleagues and helping them grow.
Meanwhile the senior developers could work on their coaching and mentoring skills while discussing advanced architectures, also allowing them to grow.
Seems like a win-win, right?&lt;/p&gt;

&lt;p&gt;This scientific project will run for at least two years and we can’t wait to see what kind of insights will be revealed and the impact we will make on our environment and society!&lt;/p&gt;

&lt;p&gt;We also ended up getting some national press coverage. As you can imagine, this made us very proud!&lt;/p&gt;

&lt;p&gt;https://www.vrt.be/vrtnws/nl/2020/02/28/opnieuw-fluoplastic-in-schelde/
https://www.hln.be/in-de-buurt/antwerpen/wetenschappers-gooien-plastic-in-de-schelde-in-strijd-tegen-plasticvervuiling~a39b64e0/&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Bas&quot;, &quot;last_name&quot;=&gt;&quot;Moorkens&quot;, &quot;permalink&quot;=&gt;&quot;/author/bas-moorkens/&quot;, &quot;title&quot;=&gt;&quot;Senior Java Developer&quot;, &quot;title2&quot;=&gt;&quot;DevOps Engineer&quot;, &quot;email&quot;=&gt;&quot;bas.moorkens@ordina.be&quot;, &quot;linkedin&quot;=&gt;&quot;basmoorkens&quot;, &quot;avatar&quot;=&gt;&quot;bas-moorkens.jpg&quot;, &quot;github&quot;=&gt;&quot;basmoorkens&quot;, &quot;bio&quot;=&gt;&quot;Bas is a cloud platform architect at Ordina Belgium who is fascinated by aws, containers and pipeline automation. He started off as a Java full stack developer but got more and more into the devOps and cloud world where he currently spends most of his time.&quot;}</name><email>bas.moorkens@ordina.be</email></author><category term="Cloud" /><category term="AWS" /><category term="EKS" /><category term="Architecture" /><category term="Ionic" /><category term="Beanstalk" /><category term="Cloudfront" /><summary type="html">Table Of Contents</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-03-16-ZPR-explained/zpr-banner.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-03-16-ZPR-explained/zpr-banner.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Chatbots - Introduction and a practical use case</title><link href="https://ordina-jworks.github.io/machine%20learning/2020/02/24/Chatbots-Introduction-and-a-Practical-Case.html" rel="alternate" type="text/html" title="Chatbots - Introduction and a practical use case" /><published>2020-02-24T00:00:00+00:00</published><updated>2020-02-24T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/machine%20learning/2020/02/24/Chatbots-Introduction-and-a-Practical-Case</id><content type="html" xml:base="https://ordina-jworks.github.io/machine%20learning/2020/02/24/Chatbots-Introduction-and-a-Practical-Case.html">&lt;blockquote&gt;
  &lt;p&gt;Chatbots, they seem to be everywhere, and yet, there are a lot of people who have no idea what they are.
I came home one day in October and told my parents and sisters I was building a chatbot at work.
Their reaction: “You’re building a what now?”. 
So I took ten minutes to explain them what a chatbot is and does.
In the end, they just said “So… It is a computer person?”. &lt;br /&gt; &lt;br /&gt;
This post will feature a high-level explanation of what chatbots are and what they do, as well as a deep dive into chatbot providers and a technical implementation. 
In the end, we’ll look at a practical case of a chatbot: FleetBot Dina.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table Of Contents&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#essential-terminology&quot;&gt;Essential terminology&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#chatbot-providers&quot;&gt;Chatbot providers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#practical-case-fleetbot-dina&quot;&gt;Practical case: FleetBot Dina&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#technical-implementation&quot;&gt;Technical implementation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#resources&quot;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The concept of chatbots has existed ever since Alan Turing designed the Turing test in 1950, with the original concept of the test dating back to 1936.
The question asked in this test was “Can machines think?”. 
The test proposes a way to measure if the testee can know whether he’s talking to a human or a machine.
Joseph Weizenbaum was the first to design a real chatbot, ELIZA, in 1966 at the MIT AI laboratory, which he called a ‘chatterbot’.
Even though it failed the Turing test, the main idea behind a chatbot has since then remained the same: recognise what a user says using pre-programmed keywords and phrases, and respond accordingly.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;ELIZA&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/ELIZA.jpg&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Technology has obviously evolved a lot since 1966. 
Modern chatbots do not only look at keywords and phrases anymore.
They use a technology called &lt;a href=&quot;https://mobilecoach.com/chatterbots-6-what-is-natural-language-processing/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Natural Language Processing&lt;/a&gt; (NLP) and Understanding (NLU) to understand the meaning behind what a user says. 
NLU uses complex algorithms to analyse the input, not only with predefined keywords but by using various aspects of the language and the sentence structure of the given input.&lt;/p&gt;

&lt;p&gt;This way, not only can a chatbot understand what a user says, but it can also do a sentiment analysis and extract useful information out of the input.
An example, when the user says &lt;em&gt;“Damn, someone drove into my &lt;strong&gt;Car Brand&lt;/strong&gt; earlier today, but it wasn’t my fault. I don’t know what I should do now.”&lt;/em&gt;, the chatbot would know that the user was quite angry, he had an accident, and he drives a &lt;strong&gt;Car Brand&lt;/strong&gt;. 
The bot’s response could be: &lt;em&gt;“I hope you’re okay. Here is a list of garages you can go to. Since it wasn’t your fault, insurance will help you figure this out.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;NLP&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/NLP.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In 2006, the world saw the first big tech company launch a chatbot called Watson.
IBM’s Watson went on to winning a game of “Jeopardy!” against all-time champions Ken Jennings and Brad Rutter in 2011.
Since then, tech giants like Apple (Siri), Google (Google Now), Amazon (Alexa) and Microsoft (Cortana) have all launched their own personal assistant chatbots with their respective NLPs.
In Belgium, Antwerp company &lt;a href=&quot;https://www.chatlayer.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Chatlayer&lt;/a&gt; provides a custom platform to build chatbots. 
They use whichever NLP is best in a given language.
For Flemish &amp;amp; Dutch, they built a custom NLP.&lt;/p&gt;

&lt;p&gt;Like all chatbots, these personal assistants have a specified set of use cases, setting alarms, playing music, reading the weather report, telling jokes,… 
If they don’t know the answer to a question, they will usually just look up whatever you asked on the internet, and give you the best response.&lt;/p&gt;

&lt;h1 id=&quot;essential-terminology&quot;&gt;Essential terminology&lt;/h1&gt;
&lt;p&gt;These are a few terms you should know when studying or working with chatbots.
They will be used throughout this blog.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Natural Language Understanding&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;NLU is the Artificial Intelligence (AI) which tries to understand the meaning behind what a user says.
It can do a sentiment analysis, extract relations between words and phrasing, do semantic parsing,…&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;NLP consists of NLU, along with extra factors like syntactic parsing. 
The key takeaway here is that NLP translates the user input to machine language and determines what a user has said.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Natural Language Generation (NLG)&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;NLG comes after the computer has understood the meaning behind the input and formulates an answer. 
This answer is usually predefined, but can vary depending on the input and the entities the bot has saved so far.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Entities&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;Entities are data that a chatbot can save during a conversation, e.g. your car brand, your tire type,…&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Expressions&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;An expression is anything that a user sends or says to the bot.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Intents&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;The intent is the purpose behind a user’s message, e.g. does the user ask for a garage, does he want to know about how to refill his AdBlue,…&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;br /&gt;
    &lt;blockquote&gt;
      &lt;p&gt;A context is used when you expect the user to reply to a bot question.
By using contexts, you can direct the conversation into a certain flow, helping both the user and the computer along.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;chatbot-providers&quot;&gt;Chatbot providers&lt;/h1&gt;
&lt;p&gt;There are multiple chatbot providers you can use when building bots. 
Each bot has its own NLP and User Interface (UI), but to the core, they all expect the developer to provide the same things: expressions, intents and flows to guide a user through the conversation.
Chatbots can be implemented via various chat clients: Messenger, Microsoft Teams, Slack, Google Assistant,…
Chatbot providers provide you with integrations in different of these clients, and usually enable you to program a custom integration using (REST) APIs.&lt;/p&gt;

&lt;p&gt;Below, the biggest chatbot providers of today are listed with their properties (at the time of writing). 
We will not discuss each in detail with how bots are built, since it is equivalent for all, only varying in the UI.
There will be links in the &lt;a href=&quot;#resources&quot;&gt;Resources&lt;/a&gt; section of this blogpost.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img alt=&quot;Dialogflow&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/DIALOGFLOW.jpg&quot; style=&quot;margin:0px auto; max-width: 200px;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://dialogflow.cloud.google.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Google DialogFlow&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Easy and free to start up;&lt;/li&gt;
    &lt;li&gt;Events possible to trigger via API, making it able to move the conversation into a certain flow easily depending on user input;&lt;/li&gt;
    &lt;li&gt;Parameters can all be asked within same intent;&lt;/li&gt;
    &lt;li&gt;Intent structure can become very complicated for bigger bots, especially when first getting into an existing project;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Responses can be customised&lt;/strong&gt; based on the supported chat clients;&lt;/li&gt;
    &lt;li&gt;Complicated responses with images, buttons, cards,… and jumping from intent to intent requires a &lt;strong&gt;lot of coding&lt;/strong&gt;;&lt;/li&gt;
    &lt;li&gt;No sentiment analysis;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;About 20 integrations supported for free out of the box&lt;/strong&gt;, both chat and voice, possible to code custom integrations via API;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Multilingual&lt;/strong&gt;, Dutch relatively ok, Flemish is difficult.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img alt=&quot;AmazonLex&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/AMAZONLEX.png&quot; style=&quot;margin:0px auto; max-width: 200px;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aws.amazon.com/lex/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Amazon Alexa/Lex&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Easy and (practically) free to start up (you do have to make an account linked to a credit card);&lt;/li&gt;
    &lt;li&gt;Built to work with &lt;strong&gt;Amazon Lambdas&lt;/strong&gt;, booking appointments etc;&lt;/li&gt;
    &lt;li&gt;Integration with Amazon Connect, CRM tools,…;&lt;/li&gt;
    &lt;li&gt;Parameters can all be asked within same intent;&lt;/li&gt;
    &lt;li&gt;No easy way to build big flows, no context possibilities;&lt;/li&gt;
    &lt;li&gt;Best for small conversations like booking an appointment;&lt;/li&gt;
    &lt;li&gt;Integration with Messenger, Slack and Twilio + API;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Single-language – only English.&lt;/strong&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img alt=&quot;AmazonLex&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/MICROSOFTPOWERVA.jpg&quot; style=&quot;margin:0px auto; max-width: 200px;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://powervirtualagents.microsoft.com/en-us/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Microsoft Luis/Power Virtual Agents&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Easy and free to start up;&lt;/li&gt;
    &lt;li&gt;Built to work with &lt;strong&gt;Dynamics 365&lt;/strong&gt;;&lt;/li&gt;
    &lt;li&gt;Easy off-handing to live chat when bot fails;&lt;/li&gt;
    &lt;li&gt;Parameters can all be asked within same block;&lt;/li&gt;
    &lt;li&gt;Easy to build big flows – Tree structure using various blocks depending on use case;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;About 15 integrations supported for free out of the box&lt;/strong&gt;, both chat and voice, possible to code custom integrations via API;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Single-language – only English&lt;/strong&gt;.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img alt=&quot;IBMWATSON&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/IBMWATSON.jpg&quot; style=&quot;margin:0px auto; max-width: 200px;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.ibm.com/watson/how-to-build-a-chatbot&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;IBM Watson&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Easy and free to start up (30 day trial);&lt;/li&gt;
    &lt;li&gt;Relatively easy to build big flows – Treelike structure using various blocks depending on use case;&lt;/li&gt;
    &lt;li&gt;Integration with Messenger, Slack, WordPress and Intercom + API;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Multilingual with Watson Language Translator&lt;/strong&gt;, Dutch relatively ok, Flemish is difficult.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img alt=&quot;CHATLAYER&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/CHATLAYER.jpg&quot; style=&quot;margin:0px auto; max-width: 200px;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.chatlayer.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Chatlayer&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Easy and free to start up (30 day trial, Chatlayer has to manually approve your request for a trial);&lt;/li&gt;
    &lt;li&gt;Easy to build big flows – Tree structure using various blocks depending on use case;&lt;/li&gt;
    &lt;li&gt;Parameters can be asked using ‘Input Validation’, on faulty type of answer. 
You can reply with a custom message to make sure the user uses the correct format;&lt;/li&gt;
    &lt;li&gt;Extensive reply capabilities;&lt;/li&gt;
    &lt;li&gt;Integration with Messenger, Google Home, WhatsApp and Intercom + API;&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Multilingual&lt;/strong&gt;, Custom NLP for Dutch/Flemish, uses best available NLP for other languages. 
Can automatically detect and understand all languages, regardless of the language you programmed the bot to understand. 
Can answer only in the languages you programmed.;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;practical-case-fleetbot-dina&quot;&gt;Practical case: FleetBot Dina&lt;/h1&gt;
&lt;p&gt;At Ordina, we have about 800 cars in our Fleet. 
These, along with everything concerning alternative modes of transport and phone subscriptions, are managed by only two people.
As you’re probably thinking right now, this sounds like quite a hefty workload, and you would be quite right.
At the time of writing this blogpost, they have to deal with up to 150 emails on a daily basis, which is only expected to rise as Ordina is constantly growing.
Since we at JWorks also have questions from time to time, but wanted to lift a bit of their workload, we decided to pitch them the idea of building a chatbot.&lt;/p&gt;

&lt;p&gt;The chatbot is to be launched to Ordina’s Microsoft Teams.
This way, everyone at Ordina could contact it without having to bother with adding it as a separate user or having to create an account on a chat client they don’t use.
Since JWorks uses Telegram for a lot of their internal communications, and we like experimenting, we decided to also build a connection to a Telegram bot.
This Telegram connection was only used in the testing of the FleetBot and to improve the accuracy of the NLP.&lt;/p&gt;

&lt;p&gt;We tested all of the chatbot providers listed in the &lt;a href=&quot;#chatbot-providers&quot;&gt;Chatbot providers&lt;/a&gt; section, and ended up choosing Chatlayer for its outstanding Flemish/Dutch NLP, because most of Ordina Belgium’s employees are Flemish speaking.
The possibility to extend that functionality to Ordina in the Netherlands was an attractive bonus.
We also wanted to be able to hand the bot over to the Fleet division when it was finished, so they could keep it up to date without us.
We felt that Chatlayer offered the best UI for maintenance by non-developers.&lt;/p&gt;

&lt;p&gt;Below is a short example of the Fleetbot in MS Teams.&lt;/p&gt;

&lt;div class=&quot;responsive-video&quot;&gt;
  &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/zgIOB8djVrM&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h1 id=&quot;technical-implementation&quot;&gt;Technical implementation&lt;/h1&gt;
&lt;p&gt;The general program structure is shown in the image below. 
We will discuss the MS Teams bot in detail later on. 
As you can see, both the Teams and Telegram adapter have their own repo &amp;amp; deployment. 
The reason behind this is that we wanted to be able to provide custom connections for any chat client without having to edit in an adapter used for another one.
Using the gateway, we can easily route the response from chatlayer to the adapter it is supposed to go to.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;GENERALLAYOUT&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/GENERALLAYOUT.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The image below shows the production environment of the FleetBot in MS Teams. 
As you can see, Teams sends an API call to our adapter, which then converts it to a message format Chatlayer accepts.
For these API calls, as well as testing, we used &lt;a href=&quot;https://nestjs.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NestJS&lt;/a&gt;, an extension of NodeJS in TypeScript.
For the Telegram adapter, we used &lt;a href=&quot;https://spring.io/projects/spring-boot&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Spring Boot&lt;/a&gt; and Java instead to experiment with different technologies.&lt;/p&gt;

&lt;p&gt;To get all useful information out of the Teams message, we use the &lt;a href=&quot;https://docs.microsoft.com/en-gb/azure/bot-service/javascript/bot-builder-javascript-quickstart?view=azure-bot-service-4.0&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Microsoft BotFramework&lt;/a&gt;. 
During this conversion, we add a prefix to the id: &lt;code class=&quot;highlighter-rouge&quot;&gt;teams-prod:&lt;/code&gt;. 
This prefix makes it possible for the Gateway to know that the message came from the Teams bot in the production environment and thus send it back to the correct bot.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;TEAMSINDETAIL&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/TEAMSINDETAIL.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The BotFramework provides methods to get a conversation’s context, and reply to the correct user using that context.
Hence, we see the &lt;code class=&quot;highlighter-rouge&quot;&gt;turnContext.sendActivities()&lt;/code&gt; method used to reply to a user.
We used the NodeJS version of the BotFramework, and used a map to save the conversation references. 
The reference gets deleted right after the reply has been sent, so we didn’t need to worry about using a database to save the conversation.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;CONVERSATIONREF&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/CONVERSATIONREF.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Since Chatlayer supports many types of replies, all of these had to be converted to the possible Teams messages.
Depending on the message type Chatlayer sent, the &lt;code class=&quot;highlighter-rouge&quot;&gt;sendActivities()&lt;/code&gt; method has to send a different Activity.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;CONTINUECONV&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/CONTINUECONV.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, there are the normal text messages, but also carousels and cards (of which there are multiple types). 
This variety can deliver very fun and engaging conversations, which can improve your user retention and experience.
Of course, the use of all these features depends heavily on the conversation topic and context.
You can see an example of all possible messages below.&lt;/p&gt;

&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img alt=&quot;TEAMS1&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/TEAMS1.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto&quot; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img alt=&quot;TEAMS2&quot; src=&quot;/img/2020-02-24-Chatbots-Introduction-and-a-Practical-Case/TEAMS2.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto&quot; /&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;After working with chatbots during the past 6 months, I’m proud of what we’ve achieved so far. 
The FleetBot is being actively tested at JWorks and looking to go live for all Ordina Belgium employees.
Because of working closely with Chatlayer on the FleetBot project, we have initiated a partnership for future chatbot projects.
There already are a number of interesting projects coming up that we’re happy to be part of.
Having tested many chatbot providers, we can confidently make an assessment of which one would be best in any use case.&lt;/p&gt;

&lt;p&gt;What I’m most excited about is the versatility of chatbots. 
Want one in Telegram or Slack? &lt;br /&gt;
No problem, we can build that connection! &lt;br /&gt;
Want one that speaks Chinese, German and English? &lt;br /&gt;
Can do!&lt;/p&gt;

&lt;p&gt;Do you think your company could use a chatbot to raise user satisfaction, reduce your FAQ workload, or for anything else it could help out with?
Get in touch with &lt;a href=&quot;mailto:frederickbousson@ordina.be?subject=[Chatbots]%20Interest%20in%20chatbot%20project&quot;&gt;Frederick Bousson&lt;/a&gt;! &lt;br /&gt;
We can help you evaluate if a chatbot is indeed the way to go for your specific case and choose the correct provider for your needs.
After that, we will assist you in building the bot and build all necessary chat client connections.&lt;/p&gt;

&lt;h1 id=&quot;resources&quot;&gt;Resources&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mobilecoach.com/chatterbots-2-history-of-chatbots/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Chatbot History&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Watson Jeopardy!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NLP Intro&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nlp.stanford.edu/~wcmac/papers/20140716-UNLU.pdf#page=8&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;NLP vs NLU&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.chatlayer.ai/wp-content/uploads/downloads/big-bots-guide-20190626.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;10 Lessons Learned From Building Big Chatbots&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Jasper&quot;, &quot;last_name&quot;=&gt;&quot;Rosiers&quot;, &quot;github&quot;=&gt;&quot;jasperrosiers&quot;, &quot;linkedin&quot;=&gt;&quot;jasper-rosiers&quot;, &quot;permalink&quot;=&gt;&quot;/author/jasper-rosiers/&quot;, &quot;avatar&quot;=&gt;&quot;jasper-rosiers.png&quot;, &quot;title&quot;=&gt;&quot;Java Consultant&quot;, &quot;email&quot;=&gt;&quot;jasper.rosiers@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Jasper is a Java Developer with a love for IoT and innovative tech. He has a lot of experience in building chatbots using various platforms and coupling them to different chat clients. He also has a passion for the Agile way of working, Scrum and communication, both inside and outside the team.&quot;}</name><email>jasper.rosiers@ordina.be</email></author><category term="Machine Learning" /><category term="Chatbots" /><category term="Chatlayer" /><category term="DialogFlow" /><category term="Spring Boot" /><category term="NestJS" /><category term="Mocking" /><category term="TypeScript" /><summary type="html">Chatbots, they seem to be everywhere, and yet, there are a lot of people who have no idea what they are. I came home one day in October and told my parents and sisters I was building a chatbot at work. Their reaction: “You’re building a what now?”. So I took ten minutes to explain them what a chatbot is and does. In the end, they just said “So… It is a computer person?”. This post will feature a high-level explanation of what chatbots are and what they do, as well as a deep dive into chatbot providers and a technical implementation. In the end, we’ll look at a practical case of a chatbot: FleetBot Dina.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/chatbot.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/chatbot.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Marrying MongoDB Atlas and AWS Lambda</title><link href="https://ordina-jworks.github.io/cloud/2020/02/19/Combining-MongoDB-and-AWS-Lambda.html" rel="alternate" type="text/html" title="Marrying MongoDB Atlas and AWS Lambda" /><published>2020-02-19T00:00:00+00:00</published><updated>2020-02-19T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/cloud/2020/02/19/Combining-MongoDB-and-AWS-Lambda</id><content type="html" xml:base="https://ordina-jworks.github.io/cloud/2020/02/19/Combining-MongoDB-and-AWS-Lambda.html">&lt;h3 id=&quot;reading-time-10-min-30-sec&quot;&gt;Reading time: 10 min 30 sec&lt;/h3&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of contents&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#mongodb-and-aws-lambda-a-successful-marriage&quot;&gt;MongoDB and AWS Lambda: a successful marriage?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mongodb-and-aws-lambda-why&quot;&gt;Why?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#mongodb-and-aws-lambda-performance&quot;&gt;Performance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cold-start-vs-warm-performance&quot;&gt;Cold start vs warm performance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#performance-conclusion&quot;&gt;Performance conclusions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vpc-peering-connect-your-lambda-functions-with-your-mongodb-atlas-cluster&quot;&gt;VPC peering between AWS and MongoDB Atlas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#useful-links&quot;&gt;Useful links&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;mongodb-and-aws-lambda-a-successful-marriage&quot;&gt;MongoDB and AWS Lambda: a successful marriage?&lt;/h1&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/rings.png&quot; width=&quot;15%&quot; height=&quot;15%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Can we use MongoDB Atlas when working with AWS Lambda?&lt;br /&gt;
Yes we can! &lt;br /&gt;
It’s simple enough to setup and above all also performing well!&lt;/p&gt;

&lt;p&gt;This blog concerns mainly two things:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Why would you use MongoDB + AWS Lambda and how does it perform&lt;/li&gt;
  &lt;li&gt;How to create a production grade setup with vpc-peering&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;why&quot;&gt;Why?&lt;/h1&gt;
&lt;p&gt;As I am both a fan of AWS Lambda and MongoDB Atlas it was fun for me to marry them.&lt;br /&gt;
However in the real world we don’t do things for fun alone.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/mongodb-plus-aws-lambda.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;What are the motives to combine MongoDB Atlas and AWS Lambda?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Combine the serverless capabilities of Lambda with the MongoDB strong points&lt;/li&gt;
  &lt;li&gt;Payment model - In case of MongoDB you provision your cluster and you know what you’ll pay for it, clusters can grow with your business without downtime or code changes.&lt;/li&gt;
  &lt;li&gt;Flexible Data Acces - MongoDB has a rich query language and aggregation framework. On top of your data in MongoDB you can build nice dashboards for business intelligence. (eg. &lt;a href=&quot;https://www.mongodb.com/products/charts&quot;&gt;MongoDB Charts&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Indexes - Supports up to 64 indexes per collection with a wide variety of index types like hash, compound, unique, array, partial, TTL, geospatial, sparse, text and wildcard indexes&lt;/li&gt;
  &lt;li&gt;Large documents allowed. A MongoDB document can be up to 16 Mb.&lt;/li&gt;
  &lt;li&gt;Performance - a built-in cache and support for lots of secondary indexes that can span across arrays and subdocuments, making virtually all queries very fast&lt;/li&gt;
  &lt;li&gt;Tunable consistency&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Observability - MongoDB exposes more than 100 different metrics and has a built-in performance advisor. Because “you can’t optimize what you can’t measure.”&lt;/li&gt;
  &lt;li&gt;Platform capabilities&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
  &lt;li&gt;Joinable documents &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;performance&quot;&gt;Performance&lt;/h1&gt;
&lt;p&gt;We are using AWS Lambda to store items in our MongoDB collection.&lt;br /&gt;
I want to measure the performance in two ways:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Our Lambda Function has to setup a connection with the MongoDB cluster.
Since we are using Lambda we have to deal with a cold start if the lambda has not been invoked shortly before.
&lt;strong&gt;How is the cold start behavior when connections to the cluster have to be setup?&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;When the Lambda has been invoked shortly before the connection is cached. 
&lt;strong&gt;How quickly does a save to the database happen when the Lambda Function is warm?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Suppose you have setup access from your Lambda Functions to your MongoDB Atlas Cluster (If you want to know how to do just that, read more about it in the second part of this post).&lt;/p&gt;

&lt;p&gt;Since we are dealing with Lambda Functions we also have to deal with a phenomenon called “cold start”. 
This is the case for any Lambda Function no matter what database it connects to.
MongoDB mentions on there &lt;a href=&quot;https://docs.atlas.mongodb.com/best-practices-connecting-to-aws-lambda/&quot;&gt;website&lt;/a&gt; that there is an initial startup delay due to this.&lt;/p&gt;

&lt;p&gt;I am testing using the following setup:&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/Architecture.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Items are coming in via requests through the API.
The &lt;code class=&quot;highlighter-rouge&quot;&gt;APILambda&lt;/code&gt; drops the items on a queue.&lt;br /&gt;
A second Lambda Function &lt;code class=&quot;highlighter-rouge&quot;&gt;SaveMongoDBLambda&lt;/code&gt; stores the items in the MongoDB database.
Of this second Lambda Function I will measure the performance:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;during a cold start&lt;/li&gt;
  &lt;li&gt;when the Lambda is already warm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other things important to know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In the above setup I limit the maximum number of concurrently running Lambda Functions instances of the &lt;code class=&quot;highlighter-rouge&quot;&gt;SaveMongoDBLambda&lt;/code&gt; to 10.&lt;/li&gt;
  &lt;li&gt;The Lambda Functions are written in &lt;code class=&quot;highlighter-rouge&quot;&gt;Java&lt;/code&gt; which will add time to the coldstart performance compared to &lt;code class=&quot;highlighter-rouge&quot;&gt;Python&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;NodeJS&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;In this case I am reading the items from the queue one by one. 
Also storing them one by one.
To optimize we would do this in batch.&lt;br /&gt;
Here we want to measure performance and we don’t want the batch size to vary.
So we store them one by one.&lt;/li&gt;
  &lt;li&gt;The lambda function runs in a VPC to be able to make a peering connection to the MongoDB Atlas Cluster.&lt;/li&gt;
  &lt;li&gt;The items that are being stored are only a few tens of bytes large.&lt;/li&gt;
  &lt;li&gt;In total 1000 items were inserted&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-results-analyzing-the-results-using-xray&quot;&gt;The results: analyzing the results using XRAY&lt;/h2&gt;
&lt;p&gt;I am using the AWS Xray SDK to trace and analyze the requests flowing through the application.&lt;/p&gt;

&lt;p&gt;Here is a graph showing you the &lt;code class=&quot;highlighter-rouge&quot;&gt;Response Distribution&lt;/code&gt; of the &lt;code class=&quot;highlighter-rouge&quot;&gt;SaveMongoDBLambda&lt;/code&gt;. 
Hence, this is the time that the Lambda Function took to execute.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/response-distribution.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We notice two things.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The graph is heavily balanced to the left. 
Most of the requests took very little time.&lt;/li&gt;
  &lt;li&gt;On the right end of the spectrum we also see a couple of request. 
This are the cold starts that occur the first time a Lambda Function is invoked.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From the XRAY service map we can see that on average the Lambda Function took 174 milliseconds to execute.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/service-map.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;cold-start-vs-warm-performance&quot;&gt;Cold start vs warm performance&lt;/h3&gt;
&lt;p&gt;We can further dissect a cold start with XRAY.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/coldstart.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;We see that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bootstrapping the runtime and code in the vpc lambda took 1.7 seconds.&lt;/li&gt;
  &lt;li&gt;The initial connection is being made to the database which takes 5 seconds. 
This connection overhead is also there when using AWS native databases.
Though then it will be smaller.&lt;/li&gt;
  &lt;li&gt;Saving the actual item took 1.1 second.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That’s for the first execution of the Lambda Function.
How does this compare against a Lambda function that is already “warm”.
This is how most invocations typically hit your Lambda Function.
This means the boostrapping is already done and the connections are initialised.&lt;br /&gt;
We can also analyse a warm lambda with XRAY.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/warm-execution.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Now we notice:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Total execution took only 18 ms!&lt;/li&gt;
  &lt;li&gt;There is no longer any initialization overhead.&lt;/li&gt;
  &lt;li&gt;Storing the item took 6 ms!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;performance-conclusions&quot;&gt;Performance conclusions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Storing items in the database when the Lambda Function is already warm is blazingly fast.&lt;/li&gt;
  &lt;li&gt;Initializing the connection in case of a cold start adds time to the cold start.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;vpc-peering-connect-your-lambda-functions-with-your-mongodb-atlas-cluster&quot;&gt;VPC peering: connect your Lambda Functions with your MongoDB Atlas Cluster&lt;/h1&gt;
&lt;p&gt;Want to know how to set up a VPC peering connection between your AWS VPC and MongoDB Atlas Cluster?
Read on..&lt;/p&gt;

&lt;p&gt;We want to deploy a production grade setup.&lt;br /&gt;
This means we won’t connect over the open internet.
We’ll setup a VPC peering connection between our Atlas Cluster and our AWS VPC.&lt;/p&gt;

&lt;h2 id=&quot;the-aws-side&quot;&gt;The AWS side&lt;/h2&gt;
&lt;p&gt;Let’s setup a new VPC.
In this VPC we will create a public subnet.&lt;br /&gt;
A route table will be associated with that subnet.
In the route table we’ll define that we want to route all database traffic through the VPC peering connection towards the Atlas cluster.&lt;/p&gt;

&lt;p&gt;In the AWS User Interface navigate to the VPC dashboard and click &lt;code class=&quot;highlighter-rouge&quot;&gt;Launch VPC Wizard&lt;/code&gt;.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/1-VPC-dashboard.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Select that you want to create a VPC with a single public subnet.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/2-VPC-with-single-public-subnet.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Specify how big you want the IP range of this VPC to be.
If you have trouble figuring out the relation between the &lt;code class=&quot;highlighter-rouge&quot;&gt;CIDR block&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;Network Range&lt;/code&gt; use one of the online converters to help you. (&lt;a href=&quot;https://www.ipaddressguide.com/cidr&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://www.ipaddressguide.com/cidr&lt;/a&gt;) )&lt;br /&gt;
Give your VPC and public subnet a name.&lt;br /&gt;
Make sure that &lt;code class=&quot;highlighter-rouge&quot;&gt;enable DNS hostnames&lt;/code&gt; is enabled.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/3-VPC-with-single-public-subnet-2.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Your VPC has been successfully created.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/4-VPC-successfully-created.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;If you now navigate to the subnet tab you see that a new subnet has been created.&lt;br /&gt;
When going to the route tables tab you see two new route tables.
That is a route table for your VPC and a route table specifically for your public subnet.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/5-new-subnet.png&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/6-new-route-tables.png&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Before we go to MongoDB Atlas get some specific data about your VPC:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;From the subnet tab write down the VPC-id and IPv4 CIDR for the new subnet that was just created.&lt;/li&gt;
  &lt;li&gt;Under the security group tab find the security group that is associated with your vpc.
Write this security group identifier down.&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/7-security-group.png&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;the-mongodb-side&quot;&gt;The MongoDB side&lt;/h2&gt;

&lt;p&gt;Setup the MongoDB cluster.
&lt;strong&gt;This has to be a dedicated cluster which means you’ll need at least an M10.&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/Setup-m10-cluster.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Wait till your cluster is set up.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/m10-is-setup.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;In the Atlas UI navigate to &lt;code class=&quot;highlighter-rouge&quot;&gt;Security&lt;/code&gt; -&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Network Access&lt;/code&gt;.&lt;br /&gt;
Hit &lt;code class=&quot;highlighter-rouge&quot;&gt;+ new peering connection&lt;/code&gt; and select AWS as cloud provider.&lt;br /&gt;
The below screen will pop up. Here you have to specify some configuration.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Account ID: your AWS account Id which you can find under the ‘My Account’ in the AWS console&lt;/li&gt;
  &lt;li&gt;VPC-id: Fill in the VPC-id that you copied from the vpc that you just created in AWS&lt;/li&gt;
  &lt;li&gt;VPC CIDR: specify the CIDR block that you used to configure your vpc with on AWS&lt;/li&gt;
  &lt;li&gt;region: the region where you created the AWS vpc&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/8-setup-peering-connection-atlas.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Hit &lt;code class=&quot;highlighter-rouge&quot;&gt;Instantiate peering&lt;/code&gt; !&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/9-pending-peering-connection.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Notice that MongoDB created an &lt;code class=&quot;highlighter-rouge&quot;&gt;Atlas CIDR&lt;/code&gt; which specifies the IP range in which your Atlas cluster will reside.  Write this down, you will need it later on.
We are connecting the Atlas IP range with the IP range of our AWS VPC, hence VPC peering.&lt;/p&gt;

&lt;p&gt;The peering connection is now pending.&lt;/p&gt;

&lt;p&gt;Go back to AWS.&lt;/p&gt;

&lt;h2 id=&quot;the-aws-side-again&quot;&gt;The AWS side (again)&lt;/h2&gt;
&lt;p&gt;In the VPC service of AWS go to &lt;code class=&quot;highlighter-rouge&quot;&gt;Peering Connections&lt;/code&gt;.&lt;br /&gt;
You will notice a new peering request with status &lt;code class=&quot;highlighter-rouge&quot;&gt;Pending Acceptance&lt;/code&gt;.&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/10-aws-peering-connection-request.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Accept this peering request!&lt;/p&gt;

&lt;p&gt;Now you have to update your routing tables.
AWS will also ask you &lt;code class=&quot;highlighter-rouge&quot;&gt;Do you want to update your routing tables&lt;/code&gt; when you accept the peering request.  Click &lt;code class=&quot;highlighter-rouge&quot;&gt;Modify my route tables now&lt;/code&gt;.
We will deploy our Lambda Functions in the public subnet of our VPC.
So we want to modify the route table that is associated with that subnet.
You can recognize that route table because it has an &lt;strong&gt;explicit subnet association&lt;/strong&gt;.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/11-modify-route-table.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Selecting the route table with an &lt;strong&gt;explicit subnet association&lt;/strong&gt; and click &lt;code class=&quot;highlighter-rouge&quot;&gt;edit routes&lt;/code&gt;.
Add a route towards your Atlas cluster as indicated in the image below.&lt;br /&gt;
What we are actually saying here is that we want to route all traffic to our Atlas cluster through the VPC peering connection.&lt;br /&gt;
As &lt;code class=&quot;highlighter-rouge&quot;&gt;Destination&lt;/code&gt; choose the Atlas CIDR and under &lt;code class=&quot;highlighter-rouge&quot;&gt;Target&lt;/code&gt; choose your VPC peering connection.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/12-edit-routes.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Updating the route table will update the status of the peering connection to &lt;strong&gt;available&lt;/strong&gt; in the Atlas UI.&lt;br /&gt;
This takes a couple of minutes.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/13-peering-available.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;deploy-your-lambda-functions&quot;&gt;Deploy your lambda functions!&lt;/h3&gt;

&lt;p&gt;Now it is time to deploy your Lambda Function in the VPC that you just configured.
This Lambda Function will connect to your MongoDB Atlas Cluster via the vpc-peering we have set up.&lt;/p&gt;

&lt;p&gt;I created a project that you can use to deploy a Lambda Function in your own vpc.
You can then use it to store items in your MongoDB collection.&lt;br /&gt;
The repository can be found &lt;a href=&quot;https://github.com/Nxtra/awslambda-mongodb-vpc-peering&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;here&lt;/a&gt;.&lt;br /&gt;
Let me be clear and state that in a real world project you don’t want the password hard coded in the connection string.
An option is to put it into &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS Secret Manager&lt;/code&gt; and have your lambda retrieve it there.&lt;/p&gt;

&lt;p&gt;You need to update certain config values in this project to make it work for your own vpc!
To deploy a Lambda Function in your VPC you have to configure the VPC config:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;use the pubic subnet that we just created&lt;/li&gt;
  &lt;li&gt;specify the security group of you AWS vpc
You also have to update the connection string.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following instructions can also be found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;README&lt;/code&gt; of the project.&lt;/p&gt;

&lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;template.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;update the environment variable that specifies the connection string, database  and collection to your own connection string, database and connection.
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    Environment:
      Variables:
        MONGODB_CONNECTION_STRING: mongodb+srv://&amp;lt;user&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;your-cluster&amp;gt;.mongodb.net/test?retryWrites=true&amp;amp;w=majority
        DATABASE: yourDatabaseName
        COLLECTION: yourCollectionName
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;update the &lt;code class=&quot;highlighter-rouge&quot;&gt;VpcConfig&lt;/code&gt; with your own vpc security group and subnet:
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    VpcConfig:
      SecurityGroupIds:
        - sg-01004aee8e2eb4f33
      SubnetIds:
        - subnet-028397e077f1f8e7a
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deploy your Lambda functions to your VPC and test them out!
Run &lt;code class=&quot;highlighter-rouge&quot;&gt;./deploy.sh&lt;/code&gt; to deploy the Lambda Function to your account.
Running this script successfully will output the URL on which you can send an item through the API towards the Lambda Function.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/stack-outputs.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;In the Lambda User Interface of the AWS Console you will now see that the Lambda Function has been deployed in the correct subnet with the right security group.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/14-lambda-in-vpc.png&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Use this URL that was outputted to trigger the Lambda Function.
This will return the &lt;code class=&quot;highlighter-rouge&quot;&gt;ObjectId&lt;/code&gt; of the item in your MongoDB collection!&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/invocation-result.png&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Yihaa! MongoDB and AWS Lambda are happily married!&lt;/p&gt;

&lt;h2 id=&quot;useful-links&quot;&gt;Useful links&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.atlas.mongodb.com/security-vpc-peering/&quot;&gt;https://docs.atlas.mongodb.com/security-vpc-peering/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/xray/&quot;&gt;https://aws.amazon.com/xray/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/compare/mongodb-dynamodb&quot;&gt;https://www.mongodb.com/compare/mongodb-dynamodb&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.educba.com/mongodb-vs-dynamodb/&quot;&gt;https://www.educba.com/mongodb-vs-dynamodb/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mongodb.com/blog/post/optimizing-aws-lambda-performance-with-mongodb-atlas-and-nodejs&quot;&gt;https://www.mongodb.com/blog/post/optimizing-aws-lambda-performance-with-mongodb-atlas-and-nodejs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;p&gt;Operations can be grouped in full ACID-compliant transactions at any scale. 
In any case, indexes are always kept in sync in realtime with the data so your users will always find and work with the latest, correct data.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Tunable consistency: a variety of consistency levels allowing client applications to select the trade-offs they want to make when it comes to the strongest consistency or the lowest latency. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Platform capabilities such as Full Text Search with Lucene, Stitch Serverless Platform with GraphQL support, Charts, managed triggers, more than 30 programming language drivers, Data Lake, analytics, Kafka 2-way connector &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Joining documents: when rich documents that are loosely coupled (users and invoices for instance) need to be queried, MongoDB can join documents together inside the database, making your code more light. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Nick&quot;, &quot;last_name&quot;=&gt;&quot;Van Hoof&quot;, &quot;permalink&quot;=&gt;&quot;/author/nick-van-hoof&quot;, &quot;avatar&quot;=&gt;&quot;nick-van-hoof.jpg&quot;, &quot;title&quot;=&gt;&quot;Java Developer&quot;, &quot;linkedin&quot;=&gt;&quot;nick-van-hoof-45337914b&quot;, &quot;email&quot;=&gt;&quot;nick.vanhoof@ordina.be&quot;, &quot;github&quot;=&gt;&quot;Nxtra&quot;, &quot;bio&quot;=&gt;&quot;Nick is passionate about cloud technology. He has major expertise in AWS and AWS serverless but he appreciates other clouds just as well. He wants to be ahead of change and thus he's also working with IoT and AI.&quot;}</name><email>nick.vanhoof@ordina.be</email></author><category term="Cloud" /><category term="MongoDB" /><category term="Cloud" /><category term="AWS" /><category term="AWS Lambda" /><category term="Serverless" /><summary type="html">Reading time: 10 min 30 sec</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/featured-image.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-02-19-Combining-MongoDB-Atlas-and-AWS-Lambda/featured-image.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">eXperience Agile 2019 - Part 2</title><link href="https://ordina-jworks.github.io/conference/2020/02/12/experience-agile-2019-part-2.html" rel="alternate" type="text/html" title="eXperience Agile 2019 - Part 2" /><published>2020-02-12T00:00:00+00:00</published><updated>2020-02-12T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/conference/2020/02/12/experience-agile-2019-part-2</id><content type="html" xml:base="https://ordina-jworks.github.io/conference/2020/02/12/experience-agile-2019-part-2.html">&lt;p&gt;Our first blogpost about the &lt;a href=&quot;https://www.experienceagile.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;eXperienceAgile conference&lt;/a&gt; covered four interesting talks.&lt;br /&gt;
However, those were not the only talks so this post will dive deeper into some of the other ones.&lt;/p&gt;

&lt;h1 id=&quot;table-of-contents&quot;&gt;Table of contents&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#leadership-in-a-scaling-agile-environment-by-leonoor-koomen---written-by-wouter-nivelle&quot;&gt;Leadership in a scaling agile environment, by Leonoor Koomen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#building-a-customer-value-engine-for-a-more-successful-company-by-mario-moreira---written-by-astrid-legrand&quot;&gt;Building a Customer Value Engine for a more Successful Company, by Mario Moreira&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#agile-fluency-project---why-focusing-teams-rock-by-diana-larsen---written-by-michaela-broeckx&quot;&gt;Agile Fluency Project - Why focusing team rock, by Diana Larsen&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;leadership-in-a-scaling-agile-environment-by-leonoor-koomen---written-by-wouter-nivelle&quot;&gt;Leadership in a scaling agile environment, by Leonoor Koomen - written by Wouter Nivelle&lt;/h2&gt;

&lt;p&gt;Another great talk from the eXperience Agile conference came from &lt;a href=&quot;https://twitter.com/agileonoor&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Leonoor Koomen&lt;/a&gt;.&lt;br /&gt;
She talked about how leadership works in an agile environment.&lt;/p&gt;

&lt;p&gt;Why do companies want to start working in an agile manner?&lt;br /&gt;
It could be these 3 very important reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It &lt;strong&gt;reduces the time to market / volume&lt;/strong&gt;. A product can be released much faster.&lt;/li&gt;
  &lt;li&gt;It &lt;strong&gt;breaks down silos&lt;/strong&gt;. People need to work together and share knowledge.&lt;/li&gt;
  &lt;li&gt;It &lt;strong&gt;increases engagement&lt;/strong&gt; from the people working in the company.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But very often, it’s more because &lt;strong&gt;agile is in fashion and because of the myth that agile will bring twice as much in half the time&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;When you read the above, it’s no surprise that agile projects often fail, as shown below.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;project-failing-reasons&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-failing-reasons.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;See the third reason, with 38%? 
Those projects fail because management doesn’t support them.&lt;br /&gt;
So leadership is very important in an agile environment!&lt;/p&gt;

&lt;p&gt;Leaders should:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bring a compelling why! Why do we do this project? What do we hope to achieve?  Why does the company exist?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;leadership-why&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-why.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bring focus, give clarity on what needs to be done, a certain direction, with measurable goals.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;leadership-focus&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-focus.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Break silos, make teams work together.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img alt=&quot;leadership-break-silos&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-silos.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Be accessible, be open for questions, criticism.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So leadership is very important and needs to inspire the various teams. Spotify is a big name and is used as an example for many companies. 
But Leonoor said:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;I hate to break it to you, but you are NOT Spotify!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While Spotify can be used for ideas, you probably have different dependencies, stakeholders, situational problems and so on.&lt;br /&gt;
It’s thus very important to come up with a plan to scale.&lt;br /&gt;
How are you going to grow and handle problems?&lt;br /&gt;
Transparency is essential, but gets more difficult when you scale.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;leadership-transparency&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-transparency.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While growing, how are you going to handle the measurement of progress?&lt;br /&gt;
The most important measurement of progress is… &lt;strong&gt;a working product&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;So stop asking for progress reports! Rather, create an environment for autonomy and alignment.&lt;br /&gt;
Give the teams autonomy to create the solution, while still providing the vision and alignment. 
Tell them what to do, but let them figure out the solution.&lt;/p&gt;

&lt;p&gt;The image below describes it perfectly.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;leadership-spotify-culture&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/leadership-spotify-culture.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The agile transformation is a challenge, but there’s hopeful news.&lt;br /&gt;
It’s a long journey, but it is possible to achieve.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Every change, no matter how big or small, starts with the same word… YOU!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;building-a-customer-value-engine-for-a-more-successful-company-by-mario-moreira---written-by-astrid-legrand&quot;&gt;Building a Customer Value Engine for a more Successful Company, by Mario Moreira - written by Astrid Legrand&lt;/h2&gt;

&lt;h3 id=&quot;intro&quot;&gt;Intro&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Building a Customer Value Engine for a more Successful Company&lt;/strong&gt; aims to give enterprise leaders tools and advice to maximize customer value with a high level of agility in their companies.&lt;/p&gt;

&lt;p&gt;Some methods explained during this workshop can also be easily used at a project level like, for instance, the five Rs model that helps to visualize the enterprise idea pipeline.&lt;/p&gt;

&lt;p&gt;This tool allows to visualize ideas and treat them from the moment the idea is evoked until the moment it is realized.&lt;br /&gt;
The process consists of five stages, Record – Reveal – Refine – Realize and Release, which corresponds to a &lt;strong&gt;break down&lt;/strong&gt; of the idea into a piece of work.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;5R Model 1&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/5R-model-1.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;recording-an-idea&quot;&gt;Recording an idea&lt;/h4&gt;
&lt;p&gt;At this stage of the process, when a new idea arises, it is documented. 
No decision has been taken on it so far, we do not know yet if this idea will be useful, if it will be accepted, developed, if it is a priority or if there are sufficient resources to work on it.&lt;/p&gt;

&lt;p&gt;During this first stage, the idea is simply recorded and documented. 
In an agile environment, not much time should be invested in this stage and particularly in the documentation because we don’t know if this idea will go further through the process.&lt;br /&gt;
This stage should then allow to understand the idea, to determine who the users and beneficiaries are and to quickly estimate the costs linked to this idea.&lt;/p&gt;

&lt;h4 id=&quot;revealing-the-idea&quot;&gt;Revealing the idea&lt;/h4&gt;
&lt;p&gt;During this stage of the process, the idea is added to the pool of ideas based on its value and priority. 
This is the moment when it is discussed and challenged among the stakeholders.&lt;/p&gt;

&lt;p&gt;The idea is refined in order to decide if the team will continue to work on it. 
Even if the idea is great, it doesn’t mean that it will be developed as constraints and dependencies may exist.&lt;/p&gt;

&lt;p&gt;It is at this stage of the process that those constraints are highlighted by the stakeholders or product owners. 
Following the discussions, the idea can be adapted in order to be realized and a team is selected to work on it.&lt;/p&gt;

&lt;h4 id=&quot;refining-the-idea&quot;&gt;Refining the idea&lt;/h4&gt;
&lt;p&gt;During the third stage, the idea is going to be more and more understood by the dedicated team. 
It is broken down into smaller and more precise increments in order to have a clear and detailed view of the idea.&lt;/p&gt;

&lt;p&gt;It is challenged and cut into new pieces of increments that are challenged as well and refined in order to create a backlog of clear functionalities the team will work on.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;5R Model 2&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/5R-model-2.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;realizing-the-idea&quot;&gt;Realizing the idea&lt;/h4&gt;
&lt;p&gt;This refined idea is then decomposed into user stories.&lt;br /&gt;
Those user stories are documented and prepared by the team with the purpose to be developed.&lt;br /&gt;
The user stories are then added to a sprint, developed and tested in a team effort.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;5R Model 3&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/5R-model-3.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;releasing-the-idea&quot;&gt;Releasing the idea&lt;/h4&gt;
&lt;p&gt;The idea has now been transformed into a product that will be presented to end users. 
At this stage, the plan drafted by marketing and sales is executed and the new increment that is now on the market, ready to be used is communicated to the potential customers.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;5R Model 4&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/5R-model-4.png&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;use-of-the-five-rs-in-my-daily-work&quot;&gt;Use of the five Rs in my daily work&lt;/h3&gt;
&lt;p&gt;As an analyst within a Scrum team, my work can be structured around the 5 Rs model as explained below.&lt;/p&gt;

&lt;h4 id=&quot;recording-the-idea&quot;&gt;Recording the idea&lt;/h4&gt;
&lt;p&gt;Let’s use a concrete example of my work. 
The ‘UnIt’ application we are building automates as much as possible the management and payments of the indemnities to insured members when they are unable to work.&lt;/p&gt;

&lt;p&gt;However, this automation has limitations. 
For instance, not all claim amounts can be calculated automatically in some complex cases. 
The idea of allowing users to make certain calculations manually has therefore been evoked and added to the pool of ideas. 
The idea has been discussed and challenged.&lt;/p&gt;

&lt;h4 id=&quot;revealing-the-idea-1&quot;&gt;Revealing the idea&lt;/h4&gt;
&lt;p&gt;The idea is now in the pool of ideas, the backlog, according to its value and priority. 
Discussions over the idea are ongoing and questions are raised.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Should users be allowed to make (all) calculations manually?&lt;/li&gt;
  &lt;li&gt;What are the risks? Are there limitations to this idea?&lt;/li&gt;
  &lt;li&gt;Are there legal constraints?&lt;/li&gt;
  &lt;li&gt;Should the idea be developed in priority, or should it wait in the pool of ideas?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Those discussions are conducted among product owners, analysts and developers. 
A sub-team is then created (with one analyst and developers) and is dedicated to the topic.&lt;br /&gt;
The needs are refined and the amount of work needed to develop the whole concept of manual calculations is estimated.&lt;/p&gt;

&lt;h4 id=&quot;refining-the-idea-1&quot;&gt;Refining the idea&lt;/h4&gt;
&lt;p&gt;The functionality needed to implement the manual calculations is now better understood by the sub-team responsible for this idea.&lt;br /&gt;
The functionality is discussed, refined and cut into smaller increments to obtain workable user stories. 
All user stories together make the manual calculations possible, but can be developed separately.&lt;/p&gt;

&lt;p&gt;The user stories are described in detail with preconditions, post-conditions, use cases for testing and dependencies, if any. 
The user stories are also technically discussed at this stage.&lt;/p&gt;

&lt;h4 id=&quot;realizing-the-idea-1&quot;&gt;Realizing the idea&lt;/h4&gt;
&lt;p&gt;User stories about the manual calculations have been presented to the entire team during a backlog refinement. 
They have been estimated with story points and because they were ready according to our Definition of Ready, they have been developed through several sprints.&lt;/p&gt;

&lt;h4 id=&quot;releasing-the-idea-1&quot;&gt;Releasing the idea&lt;/h4&gt;
&lt;p&gt;In my example, this stage happens in the demo of the new functionality for the manual calculations at the end of the sprints.&lt;br /&gt;
The manual calculations can be tested in the acceptance environment by the product owners and the final users.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An enterprise idea pipeline provides transparency of your options and allows you to quickly be aware of and respond to high-value work&lt;br /&gt;
M. Moreira&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;agile-fluency-project---why-focusing-teams-rock-by-diana-larsen---written-by-michaela-broeckx&quot;&gt;Agile Fluency Project - Why focusing teams rock, by Diana Larsen - written by Michaela Broeckx&lt;/h2&gt;

&lt;p&gt;Diana Larsen, or &lt;a href=&quot;https://twitter.com/DianaOfPortland&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;@DianaOfPortland&lt;/a&gt;, was an honourable guest at eXperience Agile conference. 
Browsing her website FutureWorks Consulting, and googling her name, it becomes clear she had an amazing journey leading up to this &lt;em&gt;Agile Fluency Project&lt;/em&gt;, throughout which you can move the &lt;em&gt;Agile Fluency Model&lt;/em&gt; from idea to implementation, a model she co-created with James Shore.&lt;/p&gt;

&lt;p&gt;The concept of &lt;em&gt;fluency&lt;/em&gt; is omnipresent in most of her talks and articles, and related to that &lt;em&gt;team collaboration&lt;/em&gt; has been one of her primary topics throughout her career.&lt;/p&gt;

&lt;h3 id=&quot;what-is-fluency&quot;&gt;What is fluency?&lt;/h3&gt;

&lt;p&gt;Fluency is routine practice mastery that persists under stress. In Lean, we would call this &lt;em&gt;kata&lt;/em&gt;.
You could say it is the skillful ease that comes from investing in learning.&lt;/p&gt;

&lt;p&gt;That investment comes down to taking the time and making the effort for deliberate practice. 
By regularly and consistently practicing a skill with increasing levels of challenge and with the intention of mastering that skill, a state of fluency can be reached. 
The key is to not give up easily, and with that intent, to keep up your practice until it becomes a second nature… a bit like practicing your cycling skills as a kid, because you long to get rid of those silly training wheels.&lt;/p&gt;

&lt;h3 id=&quot;from-team-to-organisation&quot;&gt;From team to organisation&lt;/h3&gt;
&lt;p&gt;The Agile Fluency Model fist focuses on &lt;em&gt;team fluency&lt;/em&gt;, a form of fluency that transcends the individual practice, and just like a team is more than the sum of its parts, team fluency also depends on management structures, relationships, and organizational culture, as well as the tools, technologies, and practices the teams use. 
Team fluency is what you get when highly performant teams become unconsciously competent at collaborating and co-creating. 
Fluency is the outcome of investment in learning and deliberate practice, and for team fluency this means learning together as a team.&lt;/p&gt;

&lt;p&gt;There are a few stages before your team gets to fluency. 
You need to invest in mastering the agile fundamentals to help focus as a team and you need a shift in team skills to be able to build sustainability while delivering value. 
The Fluency model helps you discover the topics you can explore and practice to improve these aspects and make these shifts.&lt;/p&gt;

&lt;p&gt;From there onwards, the picture becomes broader and from teams we move to the organisational structure and culture. 
In the model, Diana and James offer the tools to help you dig deeper into these topics, and make it more clear for organisations what could be worth investing in to optimise organisational Agility, on a systemic level. 
To embed fluency in the organisations, they point out the need to invest in a cross-organisation focus and generate a shift in organisational culture.&lt;/p&gt;

&lt;p&gt;&lt;img alt=&quot;velocity-chart&quot; src=&quot;/img/2019-11-18-experience-agile-2019-part-2/team-to-organisation.jpg&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 750px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-aim-of-this-model&quot;&gt;What is the aim of this model?&lt;/h3&gt;
&lt;p&gt;There are no recipes for the &lt;em&gt;perfect&lt;/em&gt; agile transformation. 
And so the creators of this model wanted to move beyond the agile methodology ‘wars’ on what is the best way to implement agile. 
They wanted it to be a positive, inclusive model that promotes improvement, so that it can be used to continuously grow towards more agility, as an individual, as a team, as an organisation. 
In that sense it is a model that can guide your team to help create alignment with management, and chart your own agile pathway. 
But it doesn’t have to be a path to perfection. 
The way James Shore puts it, the idea is that you get off at the right bus stop, the one that fits your needs, and offers the benefit you want for your company. 
No need to go all the way to the terminal bus stop if that is not required in your story or context. 
Therefore it is not a maturity model per se, but more of a map for a hop-on-hop-off bus.&lt;/p&gt;

&lt;p&gt;Discover more about this topic on the &lt;a href=&quot;https://www.agilefluency.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Agile Fluency Project website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Or buy a ticket to ride at Ordina. Our colleagues of &lt;a href=&quot;https://www.ordina.be/diensten/agile-enterprise/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;AgileWorks&lt;/a&gt; can help you to get on that bus!&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Wouter&quot;, &quot;last_name&quot;=&gt;&quot;Nivelle&quot;, &quot;permalink&quot;=&gt;&quot;/author/wouter-nivelle/&quot;, &quot;avatar&quot;=&gt;&quot;wouter-nivelle.jpg&quot;, &quot;title&quot;=&gt;&quot;Scrum Master&quot;, &quot;linkedin&quot;=&gt;&quot;wouter-nivelle-34a90b31&quot;, &quot;email&quot;=&gt;&quot;wouter.nivelle@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Wouter is a Scrum Master at Ordina Belgium. Passionate about agile. Eager to share knowledge. Not afraid of challenges. Always interested in learning and discovering new things.&quot;}</name><email>wouter.nivelle@ordina.be</email></author><category term="Conference" /><category term="Agile" /><category term="Conference" /><summary type="html">Our first blogpost about the eXperienceAgile conference covered four interesting talks. However, those were not the only talks so this post will dive deeper into some of the other ones.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2019-11-18-experience-agile-2019-part-2/ExperienceAgile2019Part2.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2019-11-18-experience-agile-2019-part-2/ExperienceAgile2019Part2.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Architecture Effort in Projects</title><link href="https://ordina-jworks.github.io/architecture/2020/01/28/Architecture-in-Projects.html" rel="alternate" type="text/html" title="Architecture Effort in Projects" /><published>2020-01-28T00:00:00+00:00</published><updated>2020-01-28T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2020/01/28/Architecture-in-Projects</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2020/01/28/Architecture-in-Projects.html">&lt;p&gt;An architect is someone whose job it is to link various things together in a consistent, integrated, maintainable and sustainable way dixit Tom Graves of Tetradian Consulting. It is the job of the architect to translate the requirements into an architectural model, and to keep the noses of the different stakeholders in the development process pointed in the same direction. He does this for numerous reasons:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Guiding thought in himself&lt;/li&gt;
  &lt;li&gt;Guiding thought in others&lt;/li&gt;
  &lt;li&gt;Being able to answer questions asked of the architect&lt;/li&gt;
  &lt;li&gt;Being able to examine the results of requirement gathering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The architect doesn’t guide action, he guides thought. Normally, thought precedes action, but in real life this is by no means an absolute truth. Numerous times in software development we might dive in headfirst and see where we get without thinking of how to go about it first. The term cowboy is sometimes colloquially used for this type of software engineer.  Additionally, the role of the architect is to suggest action, as well as oversee that action to ensure that it achieves its goal (quality assurance). So, the architectural process serves to support a reasoning process (guiding thought). The architect repeatedly runs through the reasoning process, either for guidance on his own decisions or for framing into context the decisions he requires from others. The overall picture of the solution needs to be coherent over all components.&lt;/p&gt;

&lt;p&gt;When thinking about when during a project the architect should play a role, the tried and tested methodology of the Stage Gate Process immediately pops up. This approach divides product development process into five main stages. In between these stages, a number of gates are defined as guardians of the progression to the next stage. They outline the considerations to be taken into account in the decision to move forward to the next stage in the process. These considerations range from quality checklists to budgetary assessment, resources availability, market competence and even compliance with company guidelines and policies. The list can be quite extensive. The architect alongside several other stakeholders is an essential gatekeeper. He enhances the list of quality assurances with considerations from an architectural standpoint and makes sure they are met before moving on to the next phase of the project.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-01-24-Architecture-in-Projects/stage-gate-process.jpg&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;The Standard Stage-Gate process (Source: Stage-Gate International)&lt;/p&gt;

&lt;p&gt;The stages typically used in this approach are the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stage 0 – Discovery/Idea Stage: The organization assesses its opportunities and capabilities in order to determine what is possible and advisable. This can be done through marketing research, innovation management, ideation sessions, blue ocean strategic efforts and other similar activities.&lt;/li&gt;
  &lt;li&gt;Stage 1 – Scoping Stage: The stakeholders determine the scope of the new product and assess its feasibility and potential.&lt;/li&gt;
  &lt;li&gt;Stage 2 – Business Case Stage: The stakeholders assess the financial aspects of costs and gains and weigh them against each other. There are numerous &lt;a href=&quot;https://www.evolute.be/thoughts/buscase.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;business case methodologies&lt;/a&gt; to do this, such as for example the &lt;a href=&quot;http://www.isaca.org/Knowledge-Center/Val-IT-IT-Value-Delivery-/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Val IT framework&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Stage 3 – Development Stage: Once the product is fleshed out in a positive business case, the development on the new product is done by one or more project teams.&lt;/li&gt;
  &lt;li&gt;Stage 4 – Test &amp;amp; Validation Stage: Often called Acceptance Testing, the various stakeholders assess the correctness and effectiveness of the newly developed product.&lt;/li&gt;
  &lt;li&gt;Stage 5 – Launch: The final stage for the product is to be put into production to start earning value for the organization.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This approach is very much keyed on the waterfall approach of software development. In order to take this approach to the new insights gathered from iterative development and agile thinking, where there is a need for smaller iterations, greater scalability and accelerated development, the people at &lt;a href=&quot;https://www.stage-gate.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Stage-Gate International&lt;/a&gt; developed a NexGen Stage Gate Model which allows for reduced stages after the initial Minimum Viable Product (MVP) launch. These smaller iterations are however also guarded by gates between each iteration.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-01-24-Architecture-in-Projects/stage-gate-nexgen.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;The NexGen Stage-Gate process (Source: Stage-Gate International)&lt;/p&gt;

&lt;p&gt;It might seem from the different illustrations that there is no gate after the Launch Stage. This is not the case. After going live there are several checks that are typically built in during the Go Live deployment as well as during a grace period after Go Live. There are no more stages to come in this model, but that doesn’t mean there is no more work to be done. A retrospective on the past project will benefit greatly from a gate checklist performed at this time, and down the line when doing a business case verification to see whether its initial assumptions holds up might also detect indicators of success/failure in this list that can be taken up the next time a business case in this context is written up. Should the need to upgrade or decommission the new solution in the future arise, this checklist could also highlight particularities otherwise forgotten that have could have an impact on these actions.&lt;/p&gt;

&lt;p&gt;Although the architect should and can play a role in every stage of the project, he tends to regard the project in a slightly different set of stages. It starts in the Plan phase where it aligns with the global analyses. It goes along with the entire design portion of the Build phase and extends further till the architecture is constructed, documented, validated and accepted. The effort ends when the solution enters the last step in its lifecycle and enters the Dispose phase. Its main activities do however change depending on which phase of the project is currently happening.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/img/2020-01-24-Architecture-in-Projects/archphases.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width:100%&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Architectural Phases of a Project&lt;/p&gt;

&lt;p&gt;The first activities of the architecture effort focus mainly on gathering all relevant requirements that might influence the design. These requirements will also form the basis for the acceptance criteria stipulated by the gates between the phases. They can be divided into functional and non-functional requirements, where the latter can be divided into technical (such as integration, quality, and infrastructure requirements) and operational requirements (such as documentation, training, and managed services requirements).&lt;/p&gt;

&lt;p&gt;The solution architect works together with domain specialists, both business and technical, to guide and constrain the business and technical analyses from a technical perspective and should assist the analysts by informing them of technical information and possibilities. Through this exercise, business knowledge is acquired and high-level business and technical requirements are produced. The requirements should be listed as SMART statements: Specific, Measurable, Achievable, Realistic, and Timely. These requirements do not only structure the technical effort, but other disciplines such as business architecture and testing as well.&lt;/p&gt;

&lt;p&gt;The first version of a Solution Architecture (and its corresponding document) should be drafted as early as the Plan phase, when a first set of requirements becomes known, and an attempt at setting the scope ensues. This is sometimes called the Solution Architecture Blueprint. Next, throughout the project lifecycle the architecture version matures with the architect gaining more insight and detail of the to-be situation of the solution. As with most deliverables of a project, the solution architecture document will mature well into the Operate phase and even a bit of the Dispose phase with activities to keep the documentation up to date with reality.&lt;/p&gt;

&lt;p&gt;The Solution Architecture will be reassessed several times during the architecture effort. It should be considered a living document. Each time new requirements are detected, new insights are gathered, or new constraints are introduced, the architecture needs to go through a cycle of validation of the new requirements/constraints, which feeds into a new version of the architecture design, followed by an architecture presentation and review event. For instance, these new requirements and insights can be derived from proofs of concept (POC), which have been executed following an earlier version of the architecture and have exposed gaps in the solution.&lt;/p&gt;

&lt;p&gt;The following activities will be undertaken by the architect to achieve a steadily maturing architecture document:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Based on the previous architecture version, the detailed analysis will be executed by the analysts and/or more specialized domain architects. The solution architect has further the responsibility to streamline the correlation between this detailed analysis and his architecture. The solution architect provides technical information to the analysts; influences and aids the analysts’ decision making.&lt;/li&gt;
  &lt;li&gt;The solution architect gathers further information concerning the business and technical requirements. The solution architect thinks together with the business analysts and technical analysts in order to make the architectural decision, which can have immediate consequence on the analyses.&lt;/li&gt;
  &lt;li&gt;The solution architect is responsible for the validation and acceptation of the final requirements documents. The acceptation of the requirements means the solution architect agrees that the requirements documents are relevant, correct, complete and unambiguous not only for architectural decisions, but also later for design and construction phases.&lt;/li&gt;
  &lt;li&gt;The architect is also responsible for the follow-up of any Proof of Concepts that are to be performed as validation for the decided architecture. Based on the results of these POCs, an adapted version of the Architecture Document might be written out containing the conclusions of the POC.&lt;/li&gt;
  &lt;li&gt;The solution architect organizes the presentation and the review session for the proposed architecture. The presentation and review session can be omitted upon the agreement and decision from a technical project manager, sparring architect and project manager.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These revisitations of the solution architecture should however be limited as much as possible in order to avoid ‘scope creep’ and unhealthy amounts of rework. And if they are not avoidable, efforts should be made to detect these changes as soon as possible in order to limit the impact these changes will have on the existing solution.&lt;/p&gt;

&lt;p&gt;In summary, an architect will have a varying workload during all phases of the project. At the beginning of the project, the architect works together with the business and technical analysts to coordinate and guide the requirements gathering and analyses, resulting in a first mature version of the architecture. Further on, the technical analysis will be based on this version of the architecture document and will consolidate all the requirements in detail under the architect’s vigil. The architect oversees the detailed technical designs and organizes any POCs that are to be performed. Recurring actualization efforts are coupled with quality assurance of the implemented designs.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Peter&quot;, &quot;last_name&quot;=&gt;&quot;De Kinder&quot;, &quot;github&quot;=&gt;&quot;peterdekinder&quot;, &quot;linkedin&quot;=&gt;&quot;peterdekinder&quot;, &quot;permalink&quot;=&gt;&quot;/author/peterdekinder/&quot;, &quot;avatar&quot;=&gt;&quot;peterdekinder.jpg&quot;, &quot;title&quot;=&gt;&quot;Solution Architect&quot;, &quot;email&quot;=&gt;&quot;peter.dekinder@ordina.be&quot;, &quot;bio&quot;=&gt;&quot;Peter is a Solution Architect with firm roots in the Java technosphere, but with a wide interest in all things architecture. His areas of specialization include Service Oriented Architectures, Business Process Management and Security.&quot;}</name><email>peter.dekinder@ordina.be</email></author><category term="Architecture" /><category term="Architecture" /><summary type="html">An architect is someone whose job it is to link various things together in a consistent, integrated, maintainable and sustainable way dixit Tom Graves of Tetradian Consulting. It is the job of the architect to translate the requirements into an architectural model, and to keep the noses of the different stakeholders in the development process pointed in the same direction. He does this for numerous reasons: Guiding thought in himself Guiding thought in others Being able to answer questions asked of the architect Being able to examine the results of requirement gathering</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2020-01-24-Architecture-in-Projects/architectureeffort.jpg" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2020-01-24-Architecture-in-Projects/architectureeffort.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">One repo to rule them all</title><link href="https://ordina-jworks.github.io/architecture/2020/01/23/Nx.html" rel="alternate" type="text/html" title="One repo to rule them all" /><published>2020-01-23T00:00:00+00:00</published><updated>2020-01-23T00:00:00+00:00</updated><id>https://ordina-jworks.github.io/architecture/2020/01/23/Nx</id><content type="html" xml:base="https://ordina-jworks.github.io/architecture/2020/01/23/Nx.html">&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot;&gt;Intro&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#monorepo&quot;&gt;Monorepo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#nx&quot;&gt;Nx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#full-stack-applications&quot;&gt;Full stack applications&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

&lt;p&gt;Imagine yourself working in a large organization with multiple teams, all working on an application that is part of the platform that the organization offers to its clients.
You get a set of requirements and start implementing your features.
After setting up your repository and all the tooling, you’re ready to go.
All goes well during the development process and you’ve come to the end to deliver your hard work.
After you’ve deployed your application on the platform, you’re introduced with a blank screen and a console log full of errors.&lt;/p&gt;

&lt;p&gt;How can this happen?
Your team followed the requirements and all the contracts that were defined to communicate with several services.
Maybe these contracts got outdated in the meantime without you knowing it?
Were there breaking changes introduced?
Or does a library you are using locally differ from the ones used in production and isn’t compatible anymore?
It’s really difficult for a large organization to manage all the separate projects and to maintain the overview of all of them.
The complexity will increase and after a while the whole platform becomes unmanageable.&lt;/p&gt;

&lt;h1 id=&quot;monorepo&quot;&gt;Monorepo&lt;/h1&gt;

&lt;p&gt;The problems mentioned above led large software companies to transition the management of their separate projects by bringing them together under one repository: the monorepo.
Inside the monorepo, you have all the applications working together while you’re developing your app.
You’ll get feedback immediately when the service you’re calling returns a different answer than expected or when the page you are navigating to is located on another path.
When you’re not sure how a service of the platform is working, you can just hop in the source code inside the repo to find out more about it.
Code sharing becomes a breeze, because all the code is available in one repository.
You don’t have to deal anymore with npm packages for shared code in your organization or with the separate configurations, pipelines and versions of the shared libs.
Because there is only one &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file, you can easily manage the versions and don’t have to deal with conflicting versions of the same dependency inside of your project.&lt;/p&gt;

&lt;p&gt;But how can you start setting up a monorepo and what tools are required to do so?
Having to manage all this code in one repo can be really tedious to set up but this is where Nx comes into play!&lt;/p&gt;

&lt;h1 id=&quot;nx&quot;&gt;Nx&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://nx.dev/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Nx&lt;/a&gt; provides you with the tools needed to help you develop in a monorepo.
Based on their own experiences, the creators of Nx set up the best practices to structure your repository in a maintainable way.
Nx is built on top of the Angular CLI, offering you a way to create workspaces and scaffolding out of your apps.
Next to Angular apps, Nx does support creating React apps, NestJS apps, and more.
You can even write your own builder to configure creating an app with the technology of your choice.&lt;/p&gt;

&lt;p&gt;The setup of the repo has to happen only once, so you don’t have the hassle of doing it yourself each time when starting a new app.
Moreover, you won’t have the risk of teams using a whole set of different tools.
This makes it more convenient to switch projects as well, because the experience over the monorepo will be more consistent.
The versions of dependencies will be consistent over the whole repository because you only have one &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file, so you don’t have to deal anymore with version conflicts of libraries that are being used in different apps.&lt;/p&gt;

&lt;p&gt;Starting with a new workspace is pretty straightforward.
Let’s imagine we want to start a webshop where we will sell Nx-phones:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npx create-nx-workspace@latest nx-phone
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Nx will scaffold our workspace.
The root of the project contains &lt;code class=&quot;highlighter-rouge&quot;&gt;apps&lt;/code&gt; where our applications will reside, &lt;code class=&quot;highlighter-rouge&quot;&gt;libs&lt;/code&gt; for code sharing between our apps and &lt;code class=&quot;highlighter-rouge&quot;&gt;tools&lt;/code&gt; that enables us to write our own schematics.
You will write most of your code inside the &lt;code class=&quot;highlighter-rouge&quot;&gt;apps&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;libs&lt;/code&gt; directories.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2019-12-02-Nx/nx-workspace.png&quot; alt=&quot;Workspace&quot; class=&quot;image&quot; style=&quot;margin:0px auto; max-width: 360px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;apps&quot;&gt;Apps&lt;/h2&gt;
&lt;p&gt;Now that our workspace is set up, we can add apps to it.
This can be done by different ways.
We will focus now on using the &lt;a href=&quot;https://cli.angular.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Angular CLI&lt;/a&gt;.
To add an Angular app, we first have to include the capability to create Angular apps with Nx.
Afterwards, we can create our first app called “shop”.&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ng add @nrwl/angular &lt;span class=&quot;nt&quot;&gt;--defaults&lt;/span&gt; // Add Angular capability
ng g @nrwl/angular:application shop // Add the shop app
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can choose the stylesheet format and automatically set up routing while doing so.
When creating a new app inside your workspace, Nx will generate both the &lt;code class=&quot;highlighter-rouge&quot;&gt;shop&lt;/code&gt; and a &lt;code class=&quot;highlighter-rouge&quot;&gt;shop-e2e&lt;/code&gt; folder for your end-to-end tests. 
Running the following command using the Nx CLI will start up the shop app locally:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nx serve shop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;libs&quot;&gt;Libs&lt;/h2&gt;
&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;libs&lt;/code&gt; folder is where your shared code will reside.
If your organisation has a component library or a design system, then that would be a good candidate to be placed under &lt;code class=&quot;highlighter-rouge&quot;&gt;libs&lt;/code&gt;.
You can also add all your code to the libs in separate modules like feature modules while using the app as a container.
Later on, you can use the features in the modules to compose your app.&lt;/p&gt;

&lt;p&gt;If you want to take a look at the full example, please check out the nx-phone workspace here:
&lt;a href=&quot;https://github.com/DimiDeKerf/nx-phone&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://github.com/DimiDeKerf/nx-phone&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;Nx supports modern tools that you’re familiar with, without the sometimes tedious way of setting them up.
You can easily use Jest and Cypress to cover your testing needs, with great CLI support.
The unit and end-to-end tests are both configured for the shop app that we’ve just created. They can be run by using &lt;code class=&quot;highlighter-rouge&quot;&gt;nx test shop&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;nx e2e shop&lt;/code&gt;, respectively.
If you want to learn more about Jest or Cypress, be sure to check out the awesome blog posts that my colleagues have wrote:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ordina-jworks.github.io/testing/2018/08/03/testing-angular-with-jest.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Testing Angular with Jest&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ordina-jworks.github.io/testing/2019/07/18/Cypress.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Cypress: a new kid on the E2E block&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code-formatting&quot;&gt;Code formatting&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/img/2019-12-02-Nx/prettier.png&quot; alt=&quot;Prettier&quot; class=&quot;image right&quot; /&gt;&lt;/p&gt;

&lt;p&gt;How do you like to have your code formatted?
There will be some differences between how others within your organization like to format their code.
Just thinking about the merge conflicts that will arise when people use different indentations may already give you shivers.&lt;/p&gt;

&lt;p&gt;Prettier comes included with Nx and is here to help you out with this.
It’s an opinionated code formatter that integrates well with most editors.
You’re tired of formatting your code before you want to commit something?
Prettier can also run in a pre-commit hook, so your code will get formatted before your commit.
More info can be found &lt;a href=&quot;https://prettier.io/docs/en/precommit.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dependency-graph&quot;&gt;Dependency graph&lt;/h2&gt;
&lt;p&gt;What if you change something in your code?
How can you be sure that your modification didn’t break another app?
This is hard to do when your apps live in separate repositories but becomes much more convenient with the help of Nx.
All your apps and libraries will be part of a dependency graph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2019-12-02-Nx/dependency_graph.png&quot; alt=&quot;Dependency graph&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 500px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The dependency graph will give you an up-to-date version of all the applications and services, and the dependencies between them.
It can also help you to get a better understanding of the architecture.&lt;/p&gt;

&lt;h2 id=&quot;building&quot;&gt;Building&lt;/h2&gt;
&lt;p&gt;When new code is introduced or something has been refactored, Nx will be able to find out which dependencies are affected by your changes.
This gives you the opportunity to only build the affected dependencies and only run the tests of those affected ones.
For your build pipeline, that means that testing the affected apps can greatly improve the build time when dealing with large workspaces.&lt;/p&gt;

&lt;p&gt;For example, if we edit something in the shop app, our dependency graph will look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2019-12-02-Nx/dependency_graph_affected.png&quot; alt=&quot;Dependency graph of affected apps&quot; class=&quot;image fit&quot; style=&quot;margin:0px auto; max-width: 500px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Targeting the affected code can be done using the affected command.
For example, if you want to run the unit tests for the affected code:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nx affected:test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Inside of your CI, you would like to compare the changes between your branch and master.
This can be done by appending the two branches to the previous command:&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nx affected:test &lt;span class=&quot;nt&quot;&gt;--base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;origin/master &lt;span class=&quot;nt&quot;&gt;--head&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;your-branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;restrictions&quot;&gt;Restrictions&lt;/h2&gt;
&lt;p&gt;You may want to categorize libraries in different domains and limit the dependencies between those domains to improve maintainability.
Nx can help you with this, by restricting access between domains or by allowing the dependency flow to go only one way around.
To configure and manage these restrictions, you can apply tags in the &lt;code class=&quot;highlighter-rouge&quot;&gt;nx.json&lt;/code&gt; file for apps and libraries.
Be aware to also update the linting rules in &lt;code class=&quot;highlighter-rouge&quot;&gt;tslint.json&lt;/code&gt; to get feedback in your editor when violating those rules.&lt;/p&gt;

&lt;h1 id=&quot;full-stack-applications&quot;&gt;Full stack applications&lt;/h1&gt;
&lt;p&gt;With a monorepo, you can have both your frontend and your backend applications under the same repository.
This enables you to share code between them.
With Nx, you can do this by using libraries like mentioned before.
These libraries will expose the code using a public API.&lt;/p&gt;

&lt;p&gt;The code inside these libraries can be imported afterwards in your apps, without having to fetch them from a npm registry.
Think about how easily you can share an interface between your frontend and backend, without having to break it on one side.
Whenever something changes in the API, both sides will get updated so they will both remain in sync.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Having worked within a monorepo myself for the last months, I really appreciate the way it improved the daily workflow.
It encourages me to write more reusable code and to keep features small.
Other teams may have the same requirements, so code can be easily migrated to libs.
It is important to manage the different features and libs though, before they turn up to be a massive dump of code that isn’t maintainable anymore.
Switching between features is much easier and accessible, since I don’t have to check out another repository or getting familiar with the way of working of another team.
Overall, I feel more connected with other developers and with the platform while building apps in the same repository.&lt;/p&gt;

&lt;p&gt;If you’re interested in setting up a monorepo, be sure to check out Nx!
It will help you tremendously with getting started.&lt;/p&gt;</content><author><name>{&quot;first_name&quot;=&gt;&quot;Dimitri&quot;, &quot;last_name&quot;=&gt;&quot;De Kerf&quot;, &quot;permalink&quot;=&gt;&quot;/author/dimitri-de-kerf&quot;, &quot;avatar&quot;=&gt;&quot;dimitri-de-kerf.jpg&quot;, &quot;title&quot;=&gt;&quot;Frontend Developer&quot;, &quot;email&quot;=&gt;&quot;dimitri.de.kerf@ordina.be&quot;, &quot;github&quot;=&gt;&quot;DimiDeKerf&quot;, &quot;bio&quot;=&gt;&quot;Dimitri is a Frontend and Mobile developer at Ordina Belgium. He enjoys writing user friendly apps in a clean, maintainable way. Dimitri loves new technologies and is eager to try them out.&quot;}</name><email>dimitri.de.kerf@ordina.be</email></author><category term="Architecture" /><category term="Monorepo" /><category term="Nx" /><category term="Angular" /><category term="NestJS" /><summary type="html">Intro Monorepo Nx Full stack applications Conclusion</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://ordina-jworks.github.io/img/2019-12-02-Nx/nx-logo.png" /><media:content medium="image" url="https://ordina-jworks.github.io/img/2019-12-02-Nx/nx-logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>